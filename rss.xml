<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title><![CDATA[Kevin Sookocheff]]></title>
        <description><![CDATA[Tinker. Tailor. Soldier. Sailor.]]></description>
        <link>http://sookocheff.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Wed, 28 May 2014 12:45:08 GMT</lastBuildDate>
        <atom:link href="http://sookocheff.com/rss.xml" rel="self" type="application/rss+xml"/>
        <author><![CDATA[Kevin Sookocheff]]></author>
        <pubDate>Wed, 28 May 2014 12:44:38 GMT</pubDate>
        <item>
            <title><![CDATA[How to bypass the auto_now property option during an ndb put]]></title>
            <description><![CDATA[<p>In App Engine the <code>auto_now</code> option sets a property to the current date/time
whenever the entity is created or updated. This is a great feature for tracking
the time when an entity was last updated. However, sometimes you may want to put
an entity without updating an <code>auto_now</code> timestamp. This article will show you
how.</p>
<p>First, let&#39;s start with a very basic ndb model with an <code>updated</code> property having
the <code>auto_now</code> option set to <code>True</code>.</p>
<pre class="highlight"><code class="hljs python"><span class="hljs-keyword">from</span> google.appengine.ext <span class="hljs-keyword">import</span> ndb

<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Article</span><span class="hljs-params">(ndb.model)</span>:</span>
    title = ndb.model.StringProperty()
    updated = ndb.model.DateTimeProperty(auto_now=<span class="hljs-keyword">True</span>)
</code></pre>
<p>Now, let&#39;s put the entity to the datastore <em>without updating the timestamp</em> and
<em>completely bypassing the <code>auto_now</code> option</em>.</p>
<pre class="highlight"><code class="hljs python">article = Article(title=<span class="hljs-string">'Python versus Ruby'</span>)
article._properties[<span class="hljs-string">'updated'</span>]._auto_now = <span class="hljs-keyword">False</span>
article.put()
</code></pre>
<p>It&#39;s pretty simple, but with caveats. Putting the entity using the code above
will store the updated entity in the instance cache (and memcache). If we get
the entity it will be retrieved from the instance cache with the <code>auto_now</code>
property still set to <code>False</code>. This can have unwanted side-effects because
subsequent updates to the entity will not trigger the <code>auto_now</code> functionality.</p>
<pre class="highlight"><code class="hljs python">article = Article(title=<span class="hljs-string">'Python versus Ruby'</span>)
article._properties[<span class="hljs-string">'updated'</span>]._auto_now = <span class="hljs-keyword">False</span>
key = article.put() <span class="hljs-comment"># Put the entity with the auto_now option set to False</span>

article = key.get() <span class="hljs-comment"># Get the entity from instance cache</span>
article.title = <span class="hljs-string">'Python versus Go'</span>
article.put() <span class="hljs-comment"># Put the entity with the auto_now option *still* set to False</span>
</code></pre>
<p>You can set the <code>auto_now</code> option to <code>True</code> again to re-enable the functionality.</p>
<pre class="highlight"><code class="hljs python">article = Article(title=<span class="hljs-string">'Python versus Ruby'</span>)
article._properties[<span class="hljs-string">'updated'</span>]._auto_now = <span class="hljs-keyword">False</span>
key = article.put()

article._properties[<span class="hljs-string">'updated'</span>]._auto_now = <span class="hljs-keyword">True</span>
article = key.get() <span class="hljs-comment"># Get the entity from instance cache</span>
article.title = <span class="hljs-string">'Python versus Go'</span>
article.put() <span class="hljs-comment"># Puts the entity with the auto_now option set to True</span>
</code></pre>
<p>For more information on ndb caching <a href="https://developers.google.com/appengine/docs/python/ndb/cache">refer to the
documentation</a>.</p>
]]></description>
            <link>http://sookocheff.com/posts/2014-05-28-how-to-bypass-the-auto-now-property-option-during-an-ndb-put</link>
            <guid isPermaLink="true">http://sookocheff.com/posts/2014-05-28-how-to-bypass-the-auto-now-property-option-during-an-ndb-put</guid>
            <dc:creator><![CDATA[Kevin Sookocheff]]></dc:creator>
            <pubDate>Wed, 28 May 2014 11:55:48 GMT</pubDate>
        </item>
        <item>
            <title><![CDATA[App Engine MapReduce API - Part 5: Using Combiners to Reduce Data Throughput]]></title>
            <description><![CDATA[<h2 id="mapreduce-api-series">MapReduce API Series</h2>
<ul>
<li><a href="http://sookocheff.com/posts/2014-04-15-app-engine-mapreduce-api-part-1-the-basics/">Part 1: The Basics</a></li>
<li><a href="http://sookocheff.com/posts/2014-04-22-app-engine-mapreduce-api-part-2-running-a-mapreduce-job-using-mapreduceyaml/">Part 2: Running a MapReduce Job Using mapreduce.yaml</a></li>
<li><a href="http://sookocheff.com/posts/2014-04-30-app-engine-mapreduce-api-part-3-programmatic-mapreduce-using-pipelines/">Part 3: Programmatic MapReduce using Pipelines</a></li>
<li><a href="http://sookocheff.com/posts/2014-05-13-app-engine-mapreduce-api-part-4-combining-sequential-mapreduce-jobs/">Part 4: Combining Sequential MapReduce Jobs</a></li>
<li><a href="http://sookocheff.com/posts/2014-05-20-app-engine-mapreduce-api-part-5-using-combiners-to-reduce-data-throughput/">Part 5: Using Combiners to Reduce Data Throughput</a></li>
</ul>
<p>So far we&#39;ve looked at using MapReduce pipelines to perform calculations over
large data sets and combined multiple pipelines in succession. In this article
we will look at how to reduce the amount of data transfer by using a combiner.</p>
<h2 id="what-is-a-combiner-">What is a combiner?</h2>
<p>A combiner is a function that takes the output of a series of map calls as input and outputs a value of the same format to be processed by the reducer. The combiner is run just before the output of the mapper is written to disk. In fact, the combiner may not be run at all if the data can reside completely in memory and so your algorithm must be able to complete with our without the combiner. By reducing the amount of data that needs to be written to disk you can increase performance of the reduce stage. </p>
<h2 id="example">Example</h2>
<p>Let&#39;s look at an example that uses a combiner to reduce data throughput. To drive this discussion we will use an example that counts the number of occurrences of a character in a string. We originally looked at this example <a href="http://sookocheff.com/posts/2014-04-30-app-engine-mapreduce-api-part-3-programmatic-mapreduce-using-pipelines/">here</a>. In this version we will only include the character or characters that occur the most. The operation will work like this: the mapper function will count the occurrence of each character in a string. The combiner will take these (key, value) pairs and output only the character or characters that appear the most. Finally, the reducer will sum those values to find our result. This contrived problem will provide a working example of a combiner.</p>
<p>Let&#39;s start with the MapReduce job from our previous example.</p>
<pre class="highlight"><code class="hljs python"><span class="hljs-string">"""
app.pipelines
"""</span>
<span class="hljs-keyword">import</span> collections

<span class="hljs-keyword">from</span> mapreduce.lib <span class="hljs-keyword">import</span> pipeline
<span class="hljs-keyword">from</span> mapreduce <span class="hljs-keyword">import</span> mapreduce_pipeline

<span class="hljs-comment">###</span>
<span class="hljs-comment">### MapReduce Pipeline</span>
<span class="hljs-comment">###</span>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">character_count_map</span><span class="hljs-params">(random_string)</span>:</span>
    <span class="hljs-string">""" yield the number of occurrences of each character in random_string. """</span>
    counter = collections.Counter(random_string)
    <span class="hljs-keyword">for</span> character <span class="hljs-keyword">in</span> counter.elements():
        <span class="hljs-keyword">yield</span> (character, counter[character])

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">character_count_reduce</span><span class="hljs-params">(key, values)</span>:</span>
    <span class="hljs-string">""" sum the number of characters found for the key. """</span>
    <span class="hljs-keyword">yield</span> (key, sum([int(i) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> values]))

<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">CountCharactersPipeline</span><span class="hljs-params">(pipeline.Pipeline)</span>:</span>
    <span class="hljs-string">""" Count the number of occurrences of a character in a set of strings. """</span>

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">run</span><span class="hljs-params">(self, *args, **kwargs)</span>:</span>
        <span class="hljs-string">""" run """</span>
        mapper_params = {
            <span class="hljs-string">"count"</span>: <span class="hljs-number">100</span>,
            <span class="hljs-string">"string_length"</span>: <span class="hljs-number">20</span>,
        }
        reducer_params = {
            <span class="hljs-string">"mime_type"</span>: <span class="hljs-string">"text/plain"</span>
        }
        output = <span class="hljs-keyword">yield</span> mapreduce_pipeline.MapreducePipeline(
            <span class="hljs-string">"character_count"</span>,
            mapper_spec=<span class="hljs-string">"app.pipelines.character_count_map"</span>,
            mapper_params=mapper_params,
            reducer_spec=<span class="hljs-string">"app.pipelines.character_count_reduce"</span>,
            reducer_params=reducer_params,
            input_reader_spec=<span class="hljs-string">"mapreduce.input_readers.RandomStringInputReader"</span>,
            output_writer_spec=<span class="hljs-string">"mapreduce.output_writers.BlobstoreOutputWriter"</span>,
            shards=<span class="hljs-number">16</span>)
</code></pre><p>Given this base we add a combiner step to the <code>MapreducePipeline</code> by passing the <code>combiner_spec</code> argument to the initialization.</p>
<pre class="highlight"><code class="hljs cs">       output = <span class="hljs-keyword">yield</span> mapreduce_pipeline.MapreducePipeline(
            <span class="hljs-string">"character_count"</span>,
            mapper_spec=<span class="hljs-string">"app.pipelines.character_count_map"</span>,
            mapper_params=mapper_params,
            reducer_spec=<span class="hljs-string">"app.pipelines.character_count_reduce"</span>,
            reducer_params=reducer_params,
            combiner_spec=<span class="hljs-string">"app.pipelines.character_count_combine"</span>,
            input_reader_spec=<span class="hljs-string">"mapreduce.input_readers.RandomStringInputReader"</span>,
            output_writer_spec=<span class="hljs-string">"mapreduce.output_writers.BlobstoreOutputWriter"</span>,
            shards=<span class="hljs-number">16</span>)
</code></pre><p>Our combine function accepts a few parameters the key, a list of values for that key and a list of previously combined results. The combiner function yields combined values that might be processed by another combiner call and that will eventually end up in the reducer function.</p>
<p>Let&#39;s write our simple combiner function. We yield only a value instead of a <code>(key, value)</code> tuple because the key is assumed to stay the same.</p>
<pre class="highlight"><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">character_count_combine</span><span class="hljs-params">(key, values, previously_combined_values)</span>:</span>
    <span class="hljs-string">""" emit the maximum value in values and previously_combined_values """</span>
    <span class="hljs-keyword">yield</span> max(values + previously_combined_values)
</code></pre><p>Our combiner function is not guaranteed to run so we need to update our reduce function to take the maximum of the list of values as well.</p>
<pre class="highlight"><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">character_count_reduce</span><span class="hljs-params">(key, values)</span>:</span>
    <span class="hljs-string">""" sum the number of characters found for the key. """</span>
    <span class="hljs-keyword">yield</span> (key, max(values))
</code></pre><p>This gives us our final pipeline using map, reduce and combine.</p>
<pre class="highlight"><code class="hljs python"><span class="hljs-comment">###</span>
<span class="hljs-comment">### MapReduce Pipeline</span>
<span class="hljs-comment">###</span>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">character_count_map</span><span class="hljs-params">(random_string)</span>:</span>
    <span class="hljs-string">""" yield the number of occurrences of each character in random_string. """</span>
    counter = collections.Counter(random_string)
    <span class="hljs-keyword">for</span> character <span class="hljs-keyword">in</span> counter.elements():
        <span class="hljs-keyword">yield</span> (character, counter[character])

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">character_count_reduce</span><span class="hljs-params">(key, values)</span>:</span>
    <span class="hljs-string">""" sum the number of characters found for the key. """</span>
    <span class="hljs-keyword">yield</span> (key, max(values))

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">character_count_combine</span><span class="hljs-params">(key, values, previously_combined_values)</span>:</span>
    <span class="hljs-string">""" emit the maximum value in values and previously_combined_values """</span>
    <span class="hljs-keyword">yield</span> max(values + previously_combined_values)

<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">CountCharactersPipeline</span><span class="hljs-params">(pipeline.Pipeline)</span>:</span>
    <span class="hljs-string">""" Count the number of occurrences of a character in a set of strings. """</span>

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">run</span><span class="hljs-params">(self, *args, **kwargs)</span>:</span>
        <span class="hljs-string">""" run """</span>
        mapper_params = {
            <span class="hljs-string">"count"</span>: <span class="hljs-number">100</span>,
            <span class="hljs-string">"string_length"</span>: <span class="hljs-number">20</span>,
        }
        reducer_params = {
            <span class="hljs-string">"mime_type"</span>: <span class="hljs-string">"text/plain"</span>
        }
        output = <span class="hljs-keyword">yield</span> mapreduce_pipeline.MapreducePipeline(
            <span class="hljs-string">"character_count"</span>,
            mapper_spec=<span class="hljs-string">"app.pipelines.character_count_map"</span>,
            mapper_params=mapper_params,
            reducer_spec=<span class="hljs-string">"app.pipelines.character_count_reduce"</span>,
            reducer_params=reducer_params,
            combiner_spec=<span class="hljs-string">"app.pipelines.character_count_combine"</span>,
            input_reader_spec=<span class="hljs-string">"mapreduce.input_readers.RandomStringInputReader"</span>,
            output_writer_spec=<span class="hljs-string">"mapreduce.output_writers.BlobstoreOutputWriter"</span>,
            shards=<span class="hljs-number">16</span>)
</code></pre>]]></description>
            <link>http://sookocheff.com/posts/2014-05-20-app-engine-mapreduce-api-part-5-using-combiners-to-reduce-data-throughput</link>
            <guid isPermaLink="true">http://sookocheff.com/posts/2014-05-20-app-engine-mapreduce-api-part-5-using-combiners-to-reduce-data-throughput</guid>
            <dc:creator><![CDATA[Kevin Sookocheff]]></dc:creator>
            <pubDate>Tue, 20 May 2014 14:54:12 GMT</pubDate>
        </item>
        <item>
            <title><![CDATA[App Engine MapReduce API - Part 4: Combining Sequential MapReduce Jobs]]></title>
            <description><![CDATA[<h2 id="mapreduce-api-series">MapReduce API Series</h2>
<ul>
<li><a href="http://sookocheff.com/posts/2014-04-15-app-engine-mapreduce-api-part-1-the-basics/">Part 1: The Basics</a></li>
<li><a href="http://sookocheff.com/posts/2014-04-22-app-engine-mapreduce-api-part-2-running-a-mapreduce-job-using-mapreduceyaml/">Part 2: Running a MapReduce Job Using mapreduce.yaml</a></li>
<li><a href="http://sookocheff.com/posts/2014-04-30-app-engine-mapreduce-api-part-3-programmatic-mapreduce-using-pipelines/">Part 3: Programmatic MapReduce using Pipelines</a></li>
<li><a href="http://sookocheff.com/posts/2014-05-13-app-engine-mapreduce-api-part-4-combining-sequential-mapreduce-jobs/">Part 4: Combining Sequential MapReduce Jobs</a></li>
<li><a href="http://sookocheff.com/posts/2014-05-20-app-engine-mapreduce-api-part-5-using-combiners-to-reduce-data-throughput/">Part 5: Using Combiners to Reduce Data Throughput</a></li>
</ul>
<p><a href="http://sookocheff.com/posts/2014-04-30-app-engine-mapreduce-api-part-3-programmatic-mapreduce-using-pipelines/">Last
time</a>
we looked at how to run a full MapReduce Pipeline to count the number of
occurrences of a character within each string. In this post we will see how to
chain multiple MapReduce Pipelines together to perform sequential tasks.</p>
<h2 id="combining-sequential-mapreduce-jobs">Combining Sequential MapReduce Jobs</h2>
<p>As a contrived example (as all examples are) let&#39;s imagine a scenario where we
want to clean up some data by deleting a business entity from the datastore.
Each business has employees stored that also need to be deleted. Our simplified
models look like this.</p>
<pre class="highlight"><code class="hljs python"><span class="hljs-keyword">from</span> google.appengine.ext <span class="hljs-keyword">import</span> ndb

<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Business</span><span class="hljs-params">(ndb.model)</span>:</span>
    <span class="hljs-string">"""
    Model representing a business which will have employees.
    """</span>
    name = ndb.StringProperty(required=<span class="hljs-keyword">True</span>)
    address = ndb.StringProperty()

<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Employee</span><span class="hljs-params">(ndb.model)</span>:</span>
    <span class="hljs-string">"""
    Model representing employees of a business.
    """</span>
    name = ndb.StringProperty(required=<span class="hljs-keyword">True</span>)
    business = ndb.StringProperty(required=<span class="hljs-keyword">True</span>)
</code></pre>
<p>Let&#39;s create a pipeline that will iterate over every business with a matching
<code>name</code> and delete all the employees from that business. We can take advantage of
the <code>filters</code> parameter of the <code>DatastoreInputReader</code> to find all employees
working at a business with a matching name.</p>
<pre class="highlight"><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">delete_employee</span><span class="hljs-params">(entity)</span>:</span>
    <span class="hljs-string">""" Delete an employee entity. """</span>
    <span class="hljs-keyword">yield</span> op.db.Delete(entity)

<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">DeleteBusinessPipeline</span><span class="hljs-params">(pipeline.Pipeline)</span>:</span>
    <span class="hljs-string">""" Delete a business. """</span>

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">run</span><span class="hljs-params">(self, business_name, **kwargs)</span>:</span>
        <span class="hljs-string">""" run """</span>
        employee_params = {
            <span class="hljs-string">"entity_kind"</span>: <span class="hljs-string">"app.pipelines.Employee"</span>,
            <span class="hljs-string">"filters"</span>: [(<span class="hljs-string">'business'</span>, <span class="hljs-string">'='</span>, business_name)],
        }
        <span class="hljs-keyword">yield</span> mapreduce_pipeline.MapperPipeline(
            <span class="hljs-string">"delete_employee"</span>,
            handler_spec=app.pipelines.delete_employee,
            input_reader_spec=<span class="hljs-string">"mapreduce.input_readers.DatastoreInputReader"</span>,
            params=employee_params,
            shards=<span class="hljs-number">2</span>)
</code></pre>
<p>This simple pipeline will delete all of the employees. We can add a second
pipeline to our execution that will delete the business by simply yielding the
return value of the first pipeline to the Pipeline API.</p>
<pre class="highlight"><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">delete_employee</span><span class="hljs-params">(entity)</span>:</span>
    <span class="hljs-string">""" Delete an employee entity. """</span>
    <span class="hljs-keyword">yield</span> op.db.Delete(entity)

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">delete_business</span><span class="hljs-params">(entity)</span>:</span>
    <span class="hljs-string">""" Delete a business entity. """</span>
    <span class="hljs-keyword">yield</span> op.db.Delete(entity)

<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">DeleteBusinessPipeline</span><span class="hljs-params">(pipeline.Pipeline)</span>:</span>
    <span class="hljs-string">""" Delete a business. """</span>

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">run</span><span class="hljs-params">(self, business_name, **kwargs)</span>:</span>
        <span class="hljs-string">""" run """</span>
        employee_params = {
            <span class="hljs-string">"entity_kind"</span>: <span class="hljs-string">"app.pipelines.Employee"</span>,
            <span class="hljs-string">"filters"</span>: [(<span class="hljs-string">'business'</span>, <span class="hljs-string">'='</span>, business_name)],
        }
        <span class="hljs-keyword">yield</span> mapreduce_pipeline.MapperPipeline(
            <span class="hljs-string">"delete_employee"</span>,
            handler_spec=app.pipelines.delete_employee,
            input_reader_spec=<span class="hljs-string">"mapreduce.input_readers.DatastoreInputReader"</span>,
            params=employee_params,
            shards=<span class="hljs-number">2</span>)

        business_params = {
            <span class="hljs-string">"entity_kind"</span>: <span class="hljs-string">"app.pipelines.Business"</span>,
            <span class="hljs-string">"filters"</span>: [(<span class="hljs-string">'name'</span>, <span class="hljs-string">'='</span>, business_name)],
        }
        <span class="hljs-keyword">yield</span> mapreduce_pipeline.MapperPipeline(
            <span class="hljs-string">"delete_business"</span>,
            handler_spec=app.pipelines.delete_business,
            input_reader_spec=<span class="hljs-string">"mapreduce.input_readers.DatastoreInputReader"</span>,
            params=business_params,
            shards=<span class="hljs-number">2</span>)
</code></pre>
<p>The return value of the MapperPipeline call is a <code>PipelineFuture</code> object. This
future will be executed once the previous future has completed. In this case our
employee deletion pipeline will complete and the business deletion future will
execute.</p>
<p>And that&#39;s all it takes to run two sequential MapReduce jobs!</p>
]]></description>
            <link>http://sookocheff.com/posts/2014-05-13-app-engine-mapreduce-api-part-4-combining-sequential-mapreduce-jobs</link>
            <guid isPermaLink="true">http://sookocheff.com/posts/2014-05-13-app-engine-mapreduce-api-part-4-combining-sequential-mapreduce-jobs</guid>
            <dc:creator><![CDATA[Kevin Sookocheff]]></dc:creator>
            <pubDate>Tue, 13 May 2014 16:40:38 GMT</pubDate>
        </item>
        <item>
            <title><![CDATA[Installing lxml on OS X Mavericks]]></title>
            <description><![CDATA[<p>I recently tried installing lxml for use within an App Engine project on OS X
Mavericks only to be hit with an error message from <code>clang</code>.</p>
<pre class="highlight"><code class="hljs http"><span class="hljs-attribute">clang</span>: <span class="hljs-string">error: unknown argument: '-mno-fused-madd' [-Wunused-command-line-argument-hard-error-in-future]</span>

<span class="livecodeserver">clang: note: this will be <span class="hljs-operator">a</span> hard error (cannot be downgraded <span class="hljs-built_in">to</span> <span class="hljs-operator">a</span> warning) <span class="hljs-operator">in</span> <span class="hljs-operator">the</span> future

error: <span class="hljs-command"><span class="hljs-keyword">command</span> <span class="hljs-string">'cc'</span> <span class="hljs-title">failed</span> <span class="hljs-title">with</span> <span class="hljs-title">exit</span> <span class="hljs-title">status</span> <span class="hljs-title">1</span></span>
</span></code></pre><p>The <code>clang</code> compiler distributed with version 5.1 of Xcode tightened up some
restrictions and turned compiler warnings into hard errors. To disable this you need to
add a specific flag to ingore these warnings when installing affected packages.</p>
<pre class="highlight"><code class="hljs lasso">ARCHFLAGS<span class="hljs-subst">=-</span>Wno<span class="hljs-attribute">-error</span><span class="hljs-subst">=</span>unused<span class="hljs-attribute">-command</span><span class="hljs-attribute">-line</span><span class="hljs-attribute">-argument</span><span class="hljs-attribute">-hard</span><span class="hljs-attribute">-error</span><span class="hljs-attribute">-in</span><span class="hljs-attribute">-future</span> pip install lxml
</code></pre>]]></description>
            <link>http://sookocheff.com/posts/2014-05-07-installing-lxml-on-os-x-mavericks</link>
            <guid isPermaLink="true">http://sookocheff.com/posts/2014-05-07-installing-lxml-on-os-x-mavericks</guid>
            <dc:creator><![CDATA[Kevin Sookocheff]]></dc:creator>
            <pubDate>Wed, 07 May 2014 16:26:45 GMT</pubDate>
        </item>
        <item>
            <title><![CDATA[App Engine MapReduce API - Part 3: Programmatic MapReduce using Pipelines]]></title>
            <description><![CDATA[<h2 id="mapreduce-api-series">MapReduce API Series</h2>
<ul>
<li><a href="http://sookocheff.com/posts/2014-04-15-app-engine-mapreduce-api-part-1-the-basics/">Part 1: The Basics</a></li>
<li><a href="http://sookocheff.com/posts/2014-04-22-app-engine-mapreduce-api-part-2-running-a-mapreduce-job-using-mapreduceyaml/">Part 2: Running a MapReduce Job Using mapreduce.yaml</a></li>
<li><a href="http://sookocheff.com/posts/2014-04-30-app-engine-mapreduce-api-part-3-programmatic-mapreduce-using-pipelines/">Part 3: Programmatic MapReduce using Pipelines</a></li>
<li><a href="http://sookocheff.com/posts/2014-05-13-app-engine-mapreduce-api-part-4-combining-sequential-mapreduce-jobs/">Part 4: Combining Sequential MapReduce Jobs</a></li>
<li><a href="http://sookocheff.com/posts/2014-05-20-app-engine-mapreduce-api-part-5-using-combiners-to-reduce-data-throughput/">Part 5: Using Combiners to Reduce Data Throughput</a></li>
</ul>
<p><a href="http://sookocheff.com/posts/2014-04-22-app-engine-mapreduce-api-part-2-running-a-mapreduce-job-using-mapreduceyaml/">In the last article</a> we examined how to run one-off tasks that operate on a large dataset using a <code>mapreduce.yaml</code> configuration file. This article will take us a step further and look at how to run a MapReduce job programmatically using the App Engine Pipeline API.</p>
<h2 id="running-a-mapper-job-using-the-app-engine-pipeline-api">Running a Mapper Job Using the App Engine Pipeline API</h2>
<p>MapReduce jobs are based on the <a href="https://code.google.com/p/appengine-pipeline/">App Engine Pipeline API</a> for connecting together time-consuming or complex workflows. We can define a pipeline for our MapReduce job to connect each stage of the MapReduce flow to one another. Let&#39;s start by defining a pipeline for our simple <code>Touch</code> job that will update the timestamp of every entity Kind we specify.</p>
<p>To create a pipeline we inherit from the <code>Pipeline</code> object.</p>
<pre class="highlight"><code class="hljs python"><span class="hljs-keyword">from</span> mapreduce.lib <span class="hljs-keyword">import</span> pipeline

<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">TouchPipeline</span><span class="hljs-params">(pipeline.Pipeline)</span>:</span>
    <span class="hljs-string">"""
    Pipeline to update the timestamp of entities.
    """</span>
    <span class="hljs-keyword">pass</span>
</code></pre>
<p>Our pipeline requires a single <code>run</code> method. Within this method we set the specification of our <code>map</code> function and yield a <code>Pipeline</code> object.</p>
<pre class="highlight"><code class="hljs python"><span class="hljs-keyword">from</span> mapreduce.lib <span class="hljs-keyword">import</span> pipeline
<span class="hljs-keyword">from</span> mapreduce <span class="hljs-keyword">import</span> mapreduce_pipeline

<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">TouchPipeline</span><span class="hljs-params">(pipeline.Pipeline)</span>:</span>
    <span class="hljs-string">"""
    Pipeline to update the timestamp of entities.
    """</span>

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">run</span><span class="hljs-params">(self, *args, **kwargs)</span>:</span>
        <span class="hljs-string">""" run """</span>
        mapper_params = {
            <span class="hljs-string">"entity_kind"</span>: <span class="hljs-string">"app.models.user.UserModel"</span>,
        }
        <span class="hljs-keyword">yield</span> mapreduce_pipeline.MapperPipeline(
            <span class="hljs-string">"Touch all entities"</span>,
            handler_spec=<span class="hljs-string">"app.pipelines.touch"</span>,
            input_reader_spec=<span class="hljs-string">"mapreduce.input_readers.DatastoreInputReader"</span>,
            params=mapper_params,
            shards=<span class="hljs-number">64</span>)
</code></pre><p>In this piece of code we define a MapperPipeline and pass it the parameters used to initialize the pipeline. The map function is specified by the<code>handler_spec</code> parameter and our InputReader is given by the <code>input_reader_spec</code> parameter.  You&#39;ll notice from our <a href="http://sookocheff.com/posts/2014-04-22-app-engine-mapreduce-api-part-2-running-a-mapreduce-job-using-mapreduceyaml/">previous article on running a MapReduce job using mapreduce.yaml</a> that the parameters passed here match the specification supplied by the <code>mapreduce.yaml</code> file in that article. In effect, we are looking at two different ways to define the same specification for a MapReduce job. The benefit of the pipelined approach here is that we can easily start our job programmatically by instantiating our <code>Pipeline</code> object and executing the <code>start()</code> method.</p>
<pre class="highlight"><code class="hljs python">pipeline = TouchPipeline()
pipeline.start()
</code></pre>
<p>Executing this code will start the MapReduce job. You can view the progress at the URL <code>/mapreduce</code>, analagous to when starting the MapReduce job through the UI using <code>mapreduce.yaml</code>.</p>
<h2 id="adding-a-reduce-step-to-our-mapreduce-job">Adding a Reduce Step to Our MapReduce Job</h2>
<p>The previous example uses a <code>MapperPipeline</code> to define a job that executes a map function on every entity of a certain Kind. What about reduce? For this we turn to the <code>MapreducePipeline</code> object. This object accepts parameters for a <code>mapper_spec</code> and a <code>reducer_spec</code>. We can use this pipeline to perform a full MapReduce job. To make this discussion concrete and generate some useable code let&#39;s use a feature built in to the MapReduce library especially for testing, the <code>RandomStringInputReader</code>.</p>
<p>The <code>RandomStringInputReader</code> generates <code>x</code> random strings of <code>y</code> length. <code>x</code> and <code>y</code> are both parameters we can use to control the reader.  We can use this reader to create an example application that counts the number of occurrences of each character found in a random string.</p>
<p>For example, given ten random strings 20 characters in length</p>
<pre class="highlight"><code class="hljs undefined">nzkeasmekjwewmvxgdre
pczrbnzpacpwxpmiffgw
kwsufcunznnzwqmfbszu
gmmfhvikvexnamjorxod
hpaedhjzuziouxaplnmp
thurvybxiuxaskoxjvco
ovwbokvfjiuoawyavpbs
hymsucnolibdivisotrt
durcotpoydwvkvtyyudl
fujkmdenoexximucikfv
</code></pre><p>we want to find the total occurrences of each character.</p>
<pre class="highlight"><code class="hljs undefined">(n, 9)
(z, 8)
(k, 9)
etc.
</code></pre><p>Performing this calculation using MapReduce implies a two step process. First, the map function will count the number of occurrences of each letter in a given string. Second, the reduce function will sum these numbers for all strings to find the final result.</p>
<p>Let&#39;s start by setting up a <code>MapreducePipeline</code> object using the <code>RandomStringInputReader</code> reader as our <code>input_reader_spec</code> along with a skeleton <code>map</code> and <code>reduce</code> function. </p>
<pre class="highlight"><code class="hljs python"><span class="hljs-keyword">from</span> mapreduce.lib <span class="hljs-keyword">import</span> pipeline
<span class="hljs-keyword">from</span> mapreduce <span class="hljs-keyword">import</span> mapreduce_pipeline

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">character_count_map</span><span class="hljs-params">(random_string)</span>:</span>
    <span class="hljs-keyword">pass</span>

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">character_count_reduce</span><span class="hljs-params">(key, values)</span>:</span>
    <span class="hljs-keyword">pass</span>

<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">CountCharactersPipeline</span><span class="hljs-params">(pipeline.Pipeline)</span>:</span>
    <span class="hljs-string">""" Count the number of occurrences of a character. """</span>

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">run</span><span class="hljs-params">(self, *args, **kwargs)</span>:</span>
        <span class="hljs-string">""" run """</span>
        mapper_params = {
            <span class="hljs-string">"count"</span>: <span class="hljs-number">100</span>,
            <span class="hljs-string">"string_length"</span>: <span class="hljs-number">20</span>,
        }
        <span class="hljs-keyword">yield</span> mapreduce_pipeline.MapreducePipeline(
            <span class="hljs-string">"character_count"</span>,
            mapper_spec=<span class="hljs-string">"app.pipelines.character_count_map"</span>,
            mapper_params=mapper_params,
            reducer_spec=<span class="hljs-string">"app.pipelines.character_count_reduce"</span>,
            input_reader_spec=<span class="hljs-string">"mapreduce.input_readers.RandomStringInputReader"</span>,
            shards=<span class="hljs-number">16</span>)
</code></pre>
<p>We can use a standard <code>RequestHandler</code> to execute our mock MapReduce Pipeline.</p>
<pre class="highlight"><code class="hljs python"><span class="hljs-keyword">import</span> webapp2

<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">CountCharacters</span><span class="hljs-params">(webapp2.RequestHandler)</span>:</span>

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">get</span><span class="hljs-params">(self)</span>:</span>
        pipeline = CountCharactersPipeline()
        pipeline.start()
</code></pre>
<p>Let&#39;s flesh out our MapReduce template to actually count the characters in a string. To do so our map function will yield a tuple of <code>(character, count)</code> for each character encountered in our string and the number of times it was encountered. So for our input string <code>nzkeasmekjwewmvxgdre</code> we would yield <code>(n, 1)</code>, <code>(z, 1)</code>, <code>(k, 2)</code>, and so on. We update our <code>map</code> function to do this work.</p>
<pre class="highlight"><code class="hljs python"><span class="hljs-keyword">import</span> collections

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">character_count_map</span><span class="hljs-params">(random_string)</span>:</span>
    counter = collections.Counter(random_string)
    <span class="hljs-keyword">for</span> character <span class="hljs-keyword">in</span> counter.elements():
        <span class="hljs-keyword">yield</span> (character, counter[character])
</code></pre>
<p>Each tuple returned by our <code>map</code> will be fed to the Shuffle stage of the MapReduce job. The Shuffle stage groups all the values having the same key before passing the result to the <code>reduce</code> function. For example, if we yielded <code>(n, 1)</code> during one execution of our <code>map</code> function and <code>(n, 4)</code> in another execution, the Shuffle stage would group these and pass <code>n, [1, 4]</code> as the parameters to our <code>reduce</code> function (for more information on Shuffle refer to <a href="http://sookocheff.com/posts/2014-04-15-app-engine-mapreduce-api-part-1-the-basics/">Part 1 of this guide</a>).</p>
<p>Our reduce function takes the list of values returned by the Shuffle stage and
sums them.</p>
<pre class="highlight"><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">character_count_reduce</span><span class="hljs-params">(key, values)</span>:</span>
    <span class="hljs-keyword">yield</span> (key, sum([int(i) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> values]))
</code></pre>
<p>We now have a full MapReduce job that will count the occurrence of each character for a set of random strings. Running our pipeline shows the map, shuffle and reduce stages operating over our dataset.</p>
<p><a class="thumbnail" href="http://sookocheff.com/img/2014-04-30-app-engine-mapreduce-api-part-3-programmatic-mapreduce-using-pipelines/skeleton-job.png">
<img src="http://sookocheff.com/img/2014-04-30-app-engine-mapreduce-api-part-3-programmatic-mapreduce-using-pipelines/skeleton-job.png" alt="Skeleton MapReduce job.">
</a></p>
<h2 id="where-is-my-data-">Where Is My Data?</h2>
<p>How does the output of the <code>map</code> function arrive at the <code>reduce</code> function? If you look at the application logs you will see periodic writes to the blobstore.</p>
<pre class="highlight"><code class="hljs bash">Shard <span class="hljs-number">1578130350583</span>CAC16BCF-<span class="hljs-number">11</span> finalized blobstore file /blobstore/writable:RDlESEY4Q1U2UkRXT0pCVUpUTFQySlQ5VEJaTkJGUEpQS0RITVgzQ1lVREtKSzVUWTJVRlhTQjYwWFAzSE02OQ==.
Finalized name is /blobstore/<span class="hljs-number">7</span>BpFYTPsvNp95XA2uS1MlBm1DsVegjTEO9EP6TAbXZAtsxV5C7HjuZmYnqPuXdJC.
</code></pre>
<p>These writes provide the blobstore location of the intermediate results from our calculation. A <em>master</em> MapReduce task coordinates with the individual <code>map</code>, <code>shuffle</code> and <code>reduce</code> shards to share these results via blobstore keys.</p>
<h2 id="writing-our-results-with-outputwriters">Writing our Results with OutputWriters</h2>
<p>The last thing we need to finish our MapReduce job is outputting the result. To do so we add an <code>output_writer_spec</code> to our MapReduce initialization.</p>
<pre class="highlight"><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">CountCharactersPipeline</span><span class="hljs-params">(pipeline.Pipeline)</span>:</span>
    <span class="hljs-string">""" Count the number of occurrences of a character. """</span>

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">run</span><span class="hljs-params">(self, *args, **kwargs)</span>:</span>
        <span class="hljs-string">""" run """</span>
        mapper_params = {
            <span class="hljs-string">"count"</span>: <span class="hljs-number">100</span>,
            <span class="hljs-string">"string_length"</span>: <span class="hljs-number">20</span>,
        }
        <span class="hljs-keyword">yield</span> mapreduce_pipeline.MapreducePipeline(
            <span class="hljs-string">"character_count"</span>,
            mapper_spec=<span class="hljs-string">"app.pipelines.character_count_map"</span>,
            mapper_params=mapper_params,
            reducer_spec=<span class="hljs-string">"app.pipelines.character_count_reduce"</span>,
            input_reader_spec=<span class="hljs-string">"mapreduce.input_readers.RandomStringInputReader"</span>,
            output_writer_spec=<span class="hljs-string">"mapreduce.output_writers.BlobstoreOutputWriter"</span>,
            shards=<span class="hljs-number">16</span>)
</code></pre>
<p>Unfortunately we don&#39;t know where the <code>BlobstoreOutputWriter</code> saves our result. To access this we can capture the output of the <code>MapreducePipeline</code>.</p>
<pre class="highlight"><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">CountCharactersPipeline</span><span class="hljs-params">(pipeline.Pipeline)</span>:</span>
    <span class="hljs-string">""" Count the number of occurrences of a character. """</span>

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">run</span><span class="hljs-params">(self, *args, **kwargs)</span>:</span>
        <span class="hljs-string">""" run """</span>
        mapper_params = {
            <span class="hljs-string">"count"</span>: <span class="hljs-number">100</span>,
            <span class="hljs-string">"string_length"</span>: <span class="hljs-number">20</span>,
        }
        output = <span class="hljs-keyword">yield</span> mapreduce_pipeline.MapreducePipeline(
            <span class="hljs-string">"character_count"</span>,
            mapper_spec=<span class="hljs-string">"app.pipelines.character_count_map"</span>,
            mapper_params=mapper_params,
            reducer_spec=<span class="hljs-string">"app.pipelines.character_count_reduce"</span>,
            input_reader_spec=<span class="hljs-string">"mapreduce.input_readers.RandomStringInputReader"</span>,
            output_writer_spec=<span class="hljs-string">"mapreduce.output_writers.BlobstoreOutputWriter"</span>,
            shards=<span class="hljs-number">16</span>)

        <span class="hljs-keyword">yield</span> StoreOutput(output)
</code></pre>
<p><code>output</code> is a <code>PipelineFuture</code> object -- a generator that takes on a value after the execution of the <code>MapreducePipeline</code> is complete. We can access the value of this generator from within a second pipeline object that writes the location of the blobkey to the datastore for future retrievals..</p>
<pre class="highlight"><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">CharacterCounter</span><span class="hljs-params">(ndb.Model)</span>:</span>
    count = ndb.StringProperty(required=<span class="hljs-keyword">True</span>)

<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">StoreOutput</span><span class="hljs-params">(pipeline.Pipeline)</span>:</span>
    <span class="hljs-string">"""A pipeline to store the result of the MapReduce job in the database. """</span>

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">run</span><span class="hljs-params">(self, output)</span>:</span>
        counter = CharacterCounter(count=output[<span class="hljs-number">0</span>])
        counter.put()
</code></pre>
<p>This is a simplified version of the StoreOutput pipeline provided by the <a href="https://code.google.com/p/appengine-mapreduce/source/browse/trunk/python/demo/main.py#333">MapReduce Made Easy demo application</a>.</p>
<h2 id="conclusions">Conclusions</h2>
<p>In this article we&#39;ve shown how to perform a full MapReduce job using the Google App Engine MapReduce API for Python. MapReduce is a powerful abstraction to use when processing large datasets. This article should provide a good starting point for defining and running your own MapReduce jobs. For reference here is the full source code used in this post.</p>
<pre class="highlight"><code class="hljs python"><span class="hljs-string">"""
app.mapreduce
"""</span>
<span class="hljs-keyword">import</span> webapp2
<span class="hljs-keyword">import</span> collections

<span class="hljs-keyword">from</span> google.appengine.ext <span class="hljs-keyword">import</span> ndb

<span class="hljs-keyword">from</span> mapreduce.lib <span class="hljs-keyword">import</span> pipeline
<span class="hljs-keyword">from</span> mapreduce <span class="hljs-keyword">import</span> mapreduce_pipeline

<span class="hljs-comment">###</span>
<span class="hljs-comment">### Entities</span>
<span class="hljs-comment">###</span>
<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">CharacterCounter</span><span class="hljs-params">(ndb.Model)</span>:</span>
    <span class="hljs-string">""" A simple model to sotre the link to the blob storing our MapReduce output. """</span>
    count_link = ndb.StringProperty(required=<span class="hljs-keyword">True</span>)

<span class="hljs-comment">###</span>
<span class="hljs-comment">### MapReduce Pipeline</span>
<span class="hljs-comment">###</span>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">character_count_map</span><span class="hljs-params">(random_string)</span>:</span>
    <span class="hljs-string">""" yield the number of occurrences of each character in random_string. """</span>
    counter = collections.Counter(random_string)
    <span class="hljs-keyword">for</span> character <span class="hljs-keyword">in</span> counter.elements():
        <span class="hljs-keyword">yield</span> (character, counter[character])

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">character_count_reduce</span><span class="hljs-params">(key, values)</span>:</span>
    <span class="hljs-string">""" sum the number of characters found for the key. """</span>
    <span class="hljs-keyword">yield</span> (key, sum([int(i) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> values]))

<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">CountCharactersPipeline</span><span class="hljs-params">(pipeline.Pipeline)</span>:</span>
    <span class="hljs-string">""" Count the number of occurrences of a character in a set of strings. """</span>

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">run</span><span class="hljs-params">(self, *args, **kwargs)</span>:</span>
        <span class="hljs-string">""" run """</span>
        mapper_params = {
            <span class="hljs-string">"count"</span>: <span class="hljs-number">100</span>,
            <span class="hljs-string">"string_length"</span>: <span class="hljs-number">20</span>,
        }
        reducer_params = {
            <span class="hljs-string">"mime_type"</span>: <span class="hljs-string">"text/plain"</span>
        }
        output = <span class="hljs-keyword">yield</span> mapreduce_pipeline.MapreducePipeline(
            <span class="hljs-string">"character_count"</span>,
            mapper_spec=<span class="hljs-string">"app.pipelines.character_count_map"</span>,
            mapper_params=mapper_params,
            reducer_spec=<span class="hljs-string">"app.pipelines.character_count_reduce"</span>,
            reducer_params=reducer_params,
            input_reader_spec=<span class="hljs-string">"mapreduce.input_readers.RandomStringInputReader"</span>,
            output_writer_spec=<span class="hljs-string">"mapreduce.output_writers.BlobstoreOutputWriter"</span>,
            shards=<span class="hljs-number">16</span>)

        <span class="hljs-keyword">yield</span> StoreOutput(output)

<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">StoreOutput</span><span class="hljs-params">(pipeline.Pipeline)</span>:</span>
    <span class="hljs-string">""" A pipeline to store the result of the MapReduce job in the database. """</span>

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">run</span><span class="hljs-params">(self, output)</span>:</span>
        <span class="hljs-string">""" run """</span>
        counter = CharacterCounter(count_link=output[<span class="hljs-number">0</span>])
        counter.put()

<span class="hljs-comment">###</span>
<span class="hljs-comment">### Handlers</span>
<span class="hljs-comment">###</span>
<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">CountCharacters</span><span class="hljs-params">(webapp2.RequestHandler)</span>:</span>
    <span class="hljs-string">""" A handler to start the map reduce pipeline. """</span>

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">get</span><span class="hljs-params">(self)</span>:</span>
        <span class="hljs-string">""" get """</span>
        counter = CountCharactersPipeline()
        counter.start()

        redirect_url = <span class="hljs-string">"%s/status?root=%s"</span> % (counter.base_path, counter.pipeline_id)
        self.redirect(redirect_url)
</code></pre>
]]></description>
            <link>http://sookocheff.com/posts/2014-04-30-app-engine-mapreduce-api-part-3-programmatic-mapreduce-using-pipelines</link>
            <guid isPermaLink="true">http://sookocheff.com/posts/2014-04-30-app-engine-mapreduce-api-part-3-programmatic-mapreduce-using-pipelines</guid>
            <dc:creator><![CDATA[Kevin Sookocheff]]></dc:creator>
            <pubDate>Tue, 29 Apr 2014 03:51:22 GMT</pubDate>
        </item>
        <item>
            <title><![CDATA[App Engine MapReduce API - Part 2: Running a MapReduce Job Using mapreduce.yaml]]></title>
            <description><![CDATA[<h2 id="mapreduce-api-series">MapReduce API Series</h2>
<ul>
<li><a href="http://sookocheff.com/posts/2014-04-15-app-engine-mapreduce-api-part-1-the-basics/">Part 1: The Basics</a></li>
<li><a href="http://sookocheff.com/posts/2014-04-22-app-engine-mapreduce-api-part-2-running-a-mapreduce-job-using-mapreduceyaml/">Part 2: Running a MapReduce Job Using mapreduce.yaml</a></li>
<li><a href="http://sookocheff.com/posts/2014-04-30-app-engine-mapreduce-api-part-3-programmatic-mapreduce-using-pipelines/">Part 3: Programmatic MapReduce using Pipelines</a></li>
<li><a href="http://sookocheff.com/posts/2014-05-13-app-engine-mapreduce-api-part-4-combining-sequential-mapreduce-jobs/">Part 4: Combining Sequential MapReduce Jobs</a></li>
<li><a href="http://sookocheff.com/posts/2014-05-20-app-engine-mapreduce-api-part-5-using-combiners-to-reduce-data-throughput/">Part 5: Using Combiners to Reduce Data Throughput</a></li>
</ul>
<p><a href="http://sookocheff.com/posts/2014-04-15-app-engine-mapreduce-api-part-1-the-basics/">Last time</a> we looked at an overview of how MapReduce works. In this article we&#39;ll be getting our hands dirty writing some code to handle the Map Stage. If you&#39;ll recall, the Map Stage is composed of two separate components: an InputReader and a <code>map</code> function. We&#39;ll look at each of these in turn.</p>
<h2 id="getting-started-installation">Getting Started: Installation</h2>
<p>First, let&#39;s install the MapReduce API for Python. The API is constantly changing so the best way to install the latest version is to checkout the code directly from the <a href="https://code.google.com/p/appengine-mapreduce/">SVN repository</a>.</p>
<pre class="highlight"><code class="hljs bash">svn checkout http://appengine-mapreduce.googlecode.com/svn/trunk/python/src/mapreduce
</code></pre>
<p>Place the <code>mapreduce</code> folder into your application root directory and add the mapreduce handler to your <code>app.yaml</code> file.</p>
<pre class="highlight"><code class="hljs avrasm"><span class="hljs-label">includes:</span>
- lib/mapreduce/include<span class="hljs-preprocessor">.yaml</span>

<span class="hljs-label">handlers:</span>
- url: /_ah/pipeline.*
  script: mapreduce<span class="hljs-preprocessor">.lib</span><span class="hljs-preprocessor">.pipeline</span><span class="hljs-preprocessor">.handlers</span>._APP
  login: admin
</code></pre>
<p>You can verify your installation by going to the <code>/mapreduce</code> URL in your app. You&#39;ll see a UI listing the status of any MapReduce jobs. You&#39;ll also see a notice that the UI could not find the file <code>mapreduce.yaml</code>. You can ignore that notice for now.</p>
<p><a class="thumbnail" href="/img/2014-04-22-app-engine-mapreduce-api-part-2-running-a-mapreduce-job-using-mapreduceyaml/could-not-find-mapreduce.png">
<img src="/img/2014-04-22-app-engine-mapreduce-api-part-2-running-a-mapreduce-job-using-mapreduceyaml/could-not-find-mapreduce.png" alt="Could not find mapreduce.yaml">
</a></p>
<p>To get a proper view of the data you will also need to add two indexes to your <code>index.yaml</code> file to allow the MapReduce library to query for MapReduce jobs that are run via Pipelines and display them in the GUI.</p>
<pre class="highlight"><code class="hljs haml">indexes:
-<span class="ruby"> <span class="hljs-symbol">kind:</span> _AE_Pipeline_Record
</span>  properties:
  -<span class="ruby"> <span class="hljs-symbol">name:</span> is_root_pipeline
</span>  -<span class="ruby"> <span class="hljs-symbol">name:</span> start_time
</span>    direction: desc
-<span class="ruby"> <span class="hljs-symbol">kind:</span> _AE_Pipeline_Record
</span>  properties:
  -<span class="ruby"> <span class="hljs-symbol">name:</span> class_path
</span>  -<span class="ruby"> <span class="hljs-symbol">name:</span> start_time
</span>    direction: desc
</code></pre>
<h2 id="running-your-first-mapreduce-job">Running Your First MapReduce Job</h2>
<p>The easiest way to get started with MapReduce is to use the <code>mapreduce.yaml</code> file. This file allows you define a <code>mapper</code> function that will be executed for each entity passed to it. Let&#39;s go straight to an example and  create a <code>mapreduce.yaml</code> file (in your applications root directory) that will iterate over all entities of a certain Kind and put them to the datastore (updating their timestamp).</p>
<pre class="highlight"><code class="hljs avrasm"><span class="hljs-label">mapreduce:</span>
- name: Touch all entity_kind Models
  mapper:
    input_reader: mapreduce<span class="hljs-preprocessor">.input</span>_readers<span class="hljs-preprocessor">.DatastoreInputReader</span>
    handler: path_to_my<span class="hljs-preprocessor">.touch</span>
    params:
    - name: entity_kind
      default: path_to_my<span class="hljs-preprocessor">.MyModel</span>
</code></pre>
<p>Go to the <code>/mapreduce</code> URL in your app and you should see the <em>Touch all entity_kind Models</em> job selectable under the Launch job setting. </p>
<p><a class="thumbnail" href="/img/2014-04-22-app-engine-mapreduce-api-part-2-running-a-mapreduce-job-using-mapreduceyaml/select-first-mapreduce.png">
<img src="/img/2014-04-22-app-engine-mapreduce-api-part-2-running-a-mapreduce-job-using-mapreduceyaml/select-first-mapreduce.png" alt="Select first mapreduce to Launch">
</a></p>
<p>Go ahead and select this job and click <code>Run</code>. You will get an error saying that <em>MyModel</em> could not be found. </p>
<p><a class="thumbnail" href="/img/2014-04-22-app-engine-mapreduce-api-part-2-running-a-mapreduce-job-using-mapreduceyaml/could-not-find-my-model.png">
<img src="/img/2014-04-22-app-engine-mapreduce-api-part-2-running-a-mapreduce-job-using-mapreduceyaml/could-not-find-my-model.png" alt="Could not find a Model">
</a></p>
<p>This is a great time to edit your yaml file point to an actual model in your application to continue with this tutorial. Now that our InputReader is pointing to a model we can define the <code>map</code> function specified by our yaml files <code>handler</code> parameter. The <code>map</code> function is iteratively passed entities from our InputReader and we can take actions on those entities.</p>
<pre class="highlight"><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">touch</span><span class="hljs-params">(entity)</span>:</span>
    <span class="hljs-string">"""
    Update the entities timestamp.
    """</span>
    entity.put()
</code></pre>
<p>Go back to the <code>/mapreduce</code> URL in your app and run the job again. Refresh the page (if it does not auto-refresh) and you can see your job running.</p>
<p><a class="thumbnail" href="/img/2014-04-22-app-engine-mapreduce-api-part-2-running-a-mapreduce-job-using-mapreduceyaml/running-first-job.png">
<img src="/img/2014-04-22-app-engine-mapreduce-api-part-2-running-a-mapreduce-job-using-mapreduceyaml/running-first-job.png" alt="Running your first mapreduce job">
</a></p>
<p>You can click on the <code>Detail</code> link to get full details on the MapReduce job. This view gives you the status of individual shards in the MapReduce job and an overview of the processing time that was required.</p>
<p><a class="thumbnail" href="/img/2014-04-22-app-engine-mapreduce-api-part-2-running-a-mapreduce-job-using-mapreduceyaml/increment-counter.png">
<img src="/img/2014-04-22-app-engine-mapreduce-api-part-2-running-a-mapreduce-job-using-mapreduceyaml/increment-counter.png" alt="Running job details">
</a></p>
<p>We&#39;ve ran our first MapReduce job!</p>
<h2 id="the-mutationpool">The MutationPool</h2>
<p>In our <code>touch</code> function we put our entity to the datastore once for each entity. This is wasteful when the datastore allows putting multiple items at a time. To take advantage of this feature the MapReduce library offers a MutationPool that collects datastore operations to be performed in batches. </p>
<p>We can re-write our map function to take advantage of the MutationPool by yielding a database operation from within our map function. If you are unfamiliar with <code>yield</code> you can think of it as returning a value to the MapReduce job. You can have multiple <code>yield</code> statements in a function that will all return values to be handled by the MapReduce job.</p>
<pre class="highlight"><code class="hljs python"><span class="hljs-keyword">from</span> mapreduce <span class="hljs-keyword">import</span> operation <span class="hljs-keyword">as</span> op

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">touch</span><span class="hljs-params">(entity)</span>:</span>
    <span class="hljs-string">"""
    Update the entities timestamp.
    """</span>
    <span class="hljs-keyword">yield</span> op.db.Put(entity)
</code></pre>
<p> You can run the MapReduce job again and see that the job works correctly using datastore operations via the MutationPool.</p>
<p>The source code for MapReduce operations can be found in the <code>mapreduce.operation</code> module.  The <code>mapreduce.operation.db</code> module currently supports two operations via the MutationPool <code>Put</code> and <code>Delete</code>.</p>
<h2 id="counters">Counters</h2>
<p>The MapReduce library also provides counters that can be incremented when a condition is met. In our example we can count the number of entities that were touched by incrementing a counter.</p>
<pre class="highlight"><code class="hljs python"><span class="hljs-keyword">from</span> mapreduce <span class="hljs-keyword">import</span> operation <span class="hljs-keyword">as</span> op

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">touch</span><span class="hljs-params">(entity)</span>:</span>
    <span class="hljs-string">"""
    Update the entities timestamp.
    """</span>
    <span class="hljs-keyword">yield</span> op.db.Put(entity)
    <span class="hljs-keyword">yield</span> op.db.Increment(<span class="hljs-string">'touched'</span>)
</code></pre><p> All the counters that were incremented during operation of the job are listed with the job details summary.</p>
<p><a class="thumbnail" href="/img/2014-04-22-app-engine-mapreduce-api-part-2-running-a-mapreduce-job-using-mapreduceyaml/increment-counter.png">
<img src="/img/2014-04-22-app-engine-mapreduce-api-part-2-running-a-mapreduce-job-using-mapreduceyaml/increment-counter.png" alt="Incrementing a custom counter">
</a></p>
<h2 id="passing-parameters-to-the-map-function">Passing Parameters to the Map Function</h2>
<p>We can pass additional parameters to our map function by specifying them in <code>mapreduce.yaml</code>. Parameters are passed to both our InputReader and to our map handler function. In our example, we listed <code>entity_kind</code> and this parameter was expected by our InputReader and used to specify the datastore Kind processed by our InputReader. On the MapReduce status page (<code>/mapreduce</code>) we can type in a new value for this parameter to specify a different Kind before running the job.</p>
<p><a class="thumbnail" href="/img/2014-04-22-app-engine-mapreduce-api-part-2-running-a-mapreduce-job-using-mapreduceyaml/edit-parameters.png">
<img src="/img/2014-04-22-app-engine-mapreduce-api-part-2-running-a-mapreduce-job-using-mapreduceyaml/edit-parameters.png" alt="Editing job parameters">
</a></p>
<p>Let&#39;s add an additional parameter for the map function that will only touch the entity if it is older than a specific date.</p>
<pre class="highlight"><code class="hljs haml">-<span class="ruby"> <span class="hljs-symbol">name:</span> <span class="hljs-constant">Touch</span> all entity_kind <span class="hljs-constant">Models</span>
</span>  mapper:
    input_reader: mapreduce.input_readers.DatastoreInputReader
    handler: app.pipelines.touch
    params:
    -<span class="ruby"> <span class="hljs-symbol">name:</span> entity_kind
</span>      default: app.models.UserModel
    -<span class="ruby"> <span class="hljs-symbol">name:</span> if_older_than
</span>      default:
</code></pre>
<p>The mapreduce context holds the specifation for the job as defined by the <code>mapreduce.yaml</code> file. Within this context we can access our parameters.</p>
<pre class="highlight"><code class="hljs python"><span class="hljs-keyword">from</span> mapreduce <span class="hljs-keyword">import</span> operation <span class="hljs-keyword">as</span> op, context
<span class="hljs-keyword">from</span> datetime <span class="hljs-keyword">import</span> datetime

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">touch</span><span class="hljs-params">(entity)</span>:</span>
    <span class="hljs-string">"""
    Update the entities timestamp if not updated since if_older_than.
    """</span>
    params = context.get().mapreduce_spec.mapper.params
    if_older_than = params.get(<span class="hljs-string">'if_older_than'</span>)
    older_than = datetime.strptime(if_older_than, <span class="hljs-string">'%b %d %Y'</span>) <span class="hljs-keyword">if</span> if_older_than <span class="hljs-keyword">else</span> datetime.now()

    <span class="hljs-keyword">if</span> entity.updated &lt; older_than:
        <span class="hljs-keyword">yield</span> op.db.Put(entity)
        <span class="hljs-keyword">yield</span> op.counters.Increment(<span class="hljs-string">'touched'</span>)
</code></pre>
<p>Now our map function will operate on entities that have been updated previous to our <code>if_older_than</code> parameter.</p>
<h2 id="parameter-validation">Parameter Validation</h2>
<p>The MapReduce library also provides a method to do parameter validation. In our previous example we passed a date to our map function as a string. We can use a validator to validate that parameter and modify it as necessary. To use a validator function, specify it in <code>mapreduce.yaml</code> as <code>params_validator</code>.</p>
<pre class="highlight"><code class="hljs avrasm">- name: Touch all entity_kind Models
  mapper:
    input_reader: mapreduce<span class="hljs-preprocessor">.input</span>_readers<span class="hljs-preprocessor">.DatastoreInputReader</span>
    handler: app<span class="hljs-preprocessor">.pipelines</span><span class="hljs-preprocessor">.touch</span>
    params:
    - name: entity_kind
      default: app<span class="hljs-preprocessor">.models</span><span class="hljs-preprocessor">.UserModel</span>
    - name: if_older_than
      default: Jun <span class="hljs-number">1</span> <span class="hljs-number">2014</span>
    params_validator: app<span class="hljs-preprocessor">.pipelines</span><span class="hljs-preprocessor">.touch</span>_validator
</code></pre><p>The validator function accepts a single argument, a dictionary of parameters. The function can modify this dictionary and any modifications will be made available to the map function. In our example we can use the validator to attempt converting our input date into a datetime object. The <code>strptime</code> function returns a <code>ValueError</code> if it cannot convert a string to the datetime.</p>
<pre class="highlight"><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">touch_validator</span><span class="hljs-params">(user_params)</span>:</span>
    <span class="hljs-string">"""
    Validate the parameters of our map function.
    """</span>
    if_older_than = user_params[<span class="hljs-string">'if_older_than'</span>]
    datetime.strptime(if_older_than, <span class="hljs-string">'%b %d %Y'</span>)
</code></pre><p>We can trigger the validator to fail by passing in an invalid date format.</p>
<p><a class="thumbnail" href="/img/2014-04-22-app-engine-mapreduce-api-part-2-running-a-mapreduce-job-using-mapreduceyaml/failed-validator.png">
<img src="/img/2014-04-22-app-engine-mapreduce-api-part-2-running-a-mapreduce-job-using-mapreduceyaml/failed-validator.png" alt="Passing an invalid paramter">
</a></p>
<p>If parameter validation fails the MapReduce job is not started and no entities are passed from our InputReader to the map function.  </p>
<h2 id="callbacks">Callbacks</h2>
<p>The MapReduce library allows you to specify a callback function that is called after the MapReduce completes. This can be used for logging purposes or to trigger a specific event in code. The callback is specified in your <code>mapreduce.yaml</code> file as <code>done_callback</code> and points to a user specified function. This is a parameter of the MapReduce itself and not the map function -- note the independent entry in <code>mapreduce.yaml</code>.</p>
<pre class="highlight"><code class="hljs haml">-<span class="ruby"> <span class="hljs-symbol">name:</span> <span class="hljs-constant">Touch</span> all entity_kind <span class="hljs-constant">Models</span>
</span>  params:
  -<span class="ruby"> <span class="hljs-symbol">name:</span> done_callback
</span>    value: /done_touch
  mapper:
    input_reader: mapreduce.input_readers.DatastoreInputReader
    handler: app.pipelines.touch
    params:
    -<span class="ruby"> <span class="hljs-symbol">name:</span> entity_kind
</span>      default: app.models.UserModel
    -<span class="ruby"> <span class="hljs-symbol">name:</span> if_older_than
</span>      default: Jun 1 2014
    params_validator: app.pipelines.touch_validator
</code></pre>
<p>Upon completion a POST request is made to the URL given by the <code>done_callback</code> parameter. The MapReduce library sets a custom header in this request with the jobs <code>Mapreduce-Id</code>. You can use this header to retrieve details on the job that just completed. This is also a great place to do any cleanup such as deleting temporary files. In our example we will just log the original specification for this job that we set via <code>mapreduce.yaml</code></p>
<pre class="highlight"><code class="hljs python"><span class="hljs-keyword">import</span> webapp2
<span class="hljs-keyword">import</span> logging
<span class="hljs-keyword">from</span> mapreduce.model <span class="hljs-keyword">import</span> MapreduceState

<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">DoneTouch</span><span class="hljs-params">(webapp2.RequestHandler)</span>:</span>
    <span class="hljs-string">"""
    Callback function upon completion of touch MapReduce job.
    """</span>

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">post</span><span class="hljs-params">(self)</span>:</span>
        <span class="hljs-string">"""
        Log the MapReduce ID and input parameters.
        """</span>
        mapreduce_id =  self.request.headers[<span class="hljs-string">'Mapreduce-Id'</span>]           
        state = MapreduceState.get_by_key_name(mapreduce_id)   
        spec = state.mapreduce_spec
        logging.info(spec)
</code></pre>
<h2 id="additional-input-readers">Additional Input Readers</h2>
<p>In addition to the DatastoreInputReader the library includes readers for the
Blobstore, Files and Google Cloud Storage Buckets. The documentation for these
readers is scarse but you can consult the <code>mapreduce.input_readers</code> module for
more information on the expected parameters for these readers. This information
was gathered from a combination of the offical <a href="https://code.google.com/p/appengine-mapreduce/wiki/UserGuidePython#Specifying_readers">Python Users
Guide</a>
and from <a href="https://code.google.com/p/appengine-mapreduce/source/browse/trunk/python/src/mapreduce/input_readers.py">reading the
source</a>.
This should give you enough information to get started with the InputReader of
your choice.</p>
<h3 id="input-reader-reference">Input Reader Reference</h3>
<p>As a reference here is a list of InputReaders and their parameters. All
InputReaders support the <code>namespace</code> parameter for specifying the namespaces to
iterate over. If no namespace is given then all namespaces are used</p>
<dl class="dl-horizontal">
  <dt>namespace</dt>
  <dd>The list of namespaces that will be searched.</dd>
</dl>

<h4 id="blobstorelineinputreader">BlobstoreLineInputReader</h4>
<p>Input reader for a newline delimited blob in Blobstore.</p>
<dl class="dl-horizontal">
  <dt>blob_key</dt>
  <dd>The BlobKey that this input reader is processing. Either a string
  containing a single key or a list of blob key strings.</dd>
  <dt>start_position</dt>
  <dd>the line number position to start reading at.</dd>
  <dt>end_position</dt>
  <dd>The last line number position to read.</dd>
</dl>

<h4 id="blobstorezipinputreader">BlobstoreZipInputReader</h4>
<p>Input reader for files from a zip archive stored in the Blobstore. Iterates over all compressed files in a zipfile in Blobstore. </p>
<dl class="dl-horizontal">
  <dt>blob_key</dt>
  <dd>The BlobKey that this input reader is processing. Either a string
  containing a single key or a list of blob key strings.</dd>
  <dt>start_index</dt>
  <dd>the index of the first file to read.</dd>
  <dt>end_index</dt>
  <dd>The index of the last file that will not be read.</dd>
</dl>

<h4 id="blobstoreziplineinputreader">BlobstoreZipLineInputReader</h4>
<p>Input reader for files from a zip archive stored in the Blobstore. Iterates over all compressed files in a zipfile in Blobstore. Each compressed file is expected to be a newline delimited file.</p>
<dl class="dl-horizontal">
  <dt>blob_key</dt>
  <dd>The BlobKey that this input reader is processing. Either a string
  containing a single key or a list of blob key strings.</dd>
  <dt>start_file_index</dt>
  <dd>the index of the first file to read within the zip.</dd>
  <dt>end_file_index</dt>
  <dd>the index of the last file that will not be read.</dd>
  <dt>offset</dt>
  <dd>The by offset with <code>BLOB_KEY.zip[start_file_index]</code> to start reading.</dd>
</dl>

<h4 id="datastoreinputreader">DatastoreInputReader</h4>
<p>Iterates over a Model and yields model instances. Supports both db.model and ndb.model.</p>
<dl class="dl-horizontal">
  <dt>entity_kind</dt>
  <dd>the datastore kind to map over.</dd>
  <dt>keys_only</dt>
  <dd>use a keys_only query.</dd>
  <dt>batch_size</dt>
  <dd>the number of entities to read from the datastore with each batch get.</dd>
  <dt>key_range</dt>
  <dd>a range of keys to return from your query</dd>
  <dt>filters</dt>
  <dd>Any filters to apply to the datastore query.</dd>
</dl>

<h4 id="datastorekeyinputreader">DatastoreKeyInputReader</h4>
<p>Iterate over an entity kind and yields datastore.Key.</p>
<dl class="dl-horizontal">
  <dt>entity_kind</dt>
  <dd>the datastore kind to map over.</dd>
  <dt>keys_only</dt>
  <dd>use a keys_only query.</dd>
  <dt>batch_size</dt>
  <dd>the number of entities to read from the datastore with each batch get.</dd>
  <dt>key_range</dt>
  <dd>a range of keys to return from your query</dd>
  <dt>filters</dt>
  <dd>Any filters to apply to the datastore query.</dd>
</dl>

<h4 id="fileinputreader">FileInputReader</h4>
<p>Iterate over Google Cloud Storage files using the <a href="https://developers.google.com/appengine/docs/python/googlestorage/">Files API</a>.</p>
<dl class="dl-horizontal">
  <dt>files</dt>
  <dd>A list of filenames or globbed filename patterns. The format is
  <code>/gs/bucket/filename</code> or <code>/gs/bucket/prefix*</code>.</dd>
  <dt>format</dt>
  <dd>One of &quot;lines&quot;, &quot;bytes&quot;, &quot;zip&quot;. &quot;lines&quot; reads the input file line-by-line,
  &quot;bytes&quot; reads the whole file at once and &quot;zip&quot; iterates over every file within
  the zip.</dd>
</dl>

<h4 id="loginputreader">LogInputReader</h4>
<p>Input reader for a time range of logs via the <a href="https://developers.google.com/appengine/docs/python/logs/">Logs API</a>.</p>
<dl class="dl-horizontal">
  <dt>start_time</dt>
  <dd>The earliest request completion or last-update time of logs that should be mapped over, in seconds since the Unix epoch.</dd>
  <dt>end_time</dt>
  <dd>The latest request completion or last-update time that logs should be mapped over, in seconds since the Unix epoch.</dd>
  <dt>minimum_log_level</dt>
  <dd>An application log level which serves as a filter on the requests mapped over.</dd>
  <dt>include_incomplete</dt>
  <dd>Whether or not to include requests that have started but not yet finished, as a boolean.</dd>
  <dt>include_app_logs</dt>
  <dd>Whether or not to include application level logs in the mapped logs, as a boolean.</dd>
  <dt>version_ids</dt>
  <dd>A list of version ids whose logs should be read. This can not be used with module_versions</dd>
  <dt>module_versions</dt>
  <dd>A list of tuples containing a module and version id whose logs should be read. This can not be used with version_ids.</dd>
</dl>

<h4 id="namespaceinputreader">NamespaceInputReader</h4>
<p>An input reader to iterate over namespaces. This reader yields namespace names as string.</p>
<dl class="dl-horizontal">
  <dt>namespace_range</dt>
  <dd>An alphabetic range for the namespace. As defined by <a href="https://code.google.com/p/appengine-mapreduce/source/browse/trunk/python/src/mapreduce/namespace_range.py">namespace_range.py</a>.</dd>
  <dt>batch_size</dt>
  <dd>The number of namespaces to read with each batch.</dd>
</dl>

<h4 id="randomstringinputreader">RandomStringInputReader</h4>
<p>Yields random strings as output. Useful to populate output with testing entries.</p>
<dl class="dl-horizontal">
  <dt>count</dt>
  <dd>The total number of entries this reader should generate.</dd>
  <dt>string_length</dt>
  <dd>The length of the generated strings.</dd>
</dl>

<h4 id="rawdatastoreinputreader">RawDatastoreInputReader</h4>
<p>Exactly the same as DatastoreInputReader but yields a datastore.Entity.</p>
<dl class="dl-horizontal">
  <dt>entity_kind</dt>
  <dd>the datastore kind to map over.</dd>
  <dt>keys_only</dt>
  <dd>use a keys_only query.</dd>
  <dt>batch_size</dt>
  <dd>the number of entities to read from the datastore with each batch get.</dd>
  <dt>key_range</dt>
  <dd>a range of keys to return from your query</dd>
  <dt>filters</dt>
  <dd>Any filters to apply to the datastore query.</dd>
</dl>

<h4 id="recordsreader">RecordsReader</h4>
<p>Reads a list of Files API files in records format.</p>
<dl class="dl-horizontal">
  <dt>files</dt>
  <dd>A comma separated string of files to read from.</dd>
</dl>

<h2 id="conclusions">Conclusions</h2>
<p>Defining a MapReduce job via <code>mapreduce.yaml</code> provides a convenient way to
iterate over large datasets and run a function on each unit of work.
Unfortunately, running a MapDeduce job this way has a few limitations.
First, there is no way to specify a reduce phase, limiting the type of jobs we
can perform. Second, you cannot start a MapReduce job programmatically. </p>
<p>The next article in this series will show how to overcome these limitations
using MapReduce Pipelines to programmatically control your API.</p>
]]></description>
            <link>http://sookocheff.com/posts/2014-04-22-app-engine-mapreduce-api-part-2-running-a-mapreduce-job-using-mapreduceyaml</link>
            <guid isPermaLink="true">http://sookocheff.com/posts/2014-04-22-app-engine-mapreduce-api-part-2-running-a-mapreduce-job-using-mapreduceyaml</guid>
            <dc:creator><![CDATA[Kevin Sookocheff]]></dc:creator>
            <pubDate>Tue, 22 Apr 2014 12:48:36 GMT</pubDate>
        </item>
        <item>
            <title><![CDATA[App Engine MapReduce API - Part 1: The Basics]]></title>
            <description><![CDATA[<h2 id="mapreduce-api-series">MapReduce API Series</h2>
<ul>
<li><a href="http://sookocheff.com/posts/2014-04-15-app-engine-mapreduce-api-part-1-the-basics/">Part 1: The Basics</a></li>
<li><a href="http://sookocheff.com/posts/2014-04-22-app-engine-mapreduce-api-part-2-running-a-mapreduce-job-using-mapreduceyaml/">Part 2: Running a MapReduce Job Using mapreduce.yaml</a></li>
<li><a href="http://sookocheff.com/posts/2014-04-30-app-engine-mapreduce-api-part-3-programmatic-mapreduce-using-pipelines/">Part 3: Programmatic MapReduce using Pipelines</a></li>
<li><a href="http://sookocheff.com/posts/2014-05-13-app-engine-mapreduce-api-part-4-combining-sequential-mapreduce-jobs/">Part 4: Combining Sequential MapReduce Jobs</a></li>
<li><a href="http://sookocheff.com/posts/2014-05-20-app-engine-mapreduce-api-part-5-using-combiners-to-reduce-data-throughput/">Part 5: Using Combiners to Reduce Data Throughput</a></li>
</ul>
<p>The first arcticle in this series provides an overview of the <a href="https://developers.google.com/appengine/docs/python/dataprocessing/">App Engine MapReduce
API</a>. We
will give a basic overview of what MapReduce is and how it is used to do
parallel and distributed processing of large datasets.</p>
<h2 id="the-map-and-reduce-functions">The Map and Reduce Functions</h2>
<p>MapReduce is based on the <code>map</code> and <code>reduce</code> functions that are commonly used in
lazily-evaluated functional programming languages. Let&#39;s look at <code>map</code> first.</p>
<h3 id="map">map</h3>
<p>A <code>map</code> function is a way to apply a transformation to every element in a list.
Using Clojure as the example functional language we can use the <code>map</code> function
to increment every number in a list by <code>1</code>.</p>
<pre class="highlight"><code class="hljs haml">=<span class="ruby">&gt; (map inc [<span class="hljs-number">1</span> <span class="hljs-number">2</span> <span class="hljs-number">3</span> <span class="hljs-number">4</span> <span class="hljs-number">5</span>])
</span>(2 3 4 5 6)
</code></pre><p>In this example <code>inc</code> is the increment function where <code>inc(x) = x+1</code>. More
generally, you can apply any function <code>fn</code> to all elements of a list by passing
it to the map function.</p>
<pre class="highlight"><code class="hljs haml">=<span class="ruby">&gt; (map fn [<span class="hljs-number">1</span> <span class="hljs-number">2</span> <span class="hljs-number">3</span> <span class="hljs-number">4</span> <span class="hljs-number">5</span>])
</span></code></pre><h3 id="reduce">reduce</h3>
<p>Reduce applying a function <code>fn</code> of two arguments to a sequence of parameters.
Each iteration of the function call uses the value of the previous call as an
input parameter of the function. In this example we start with a base value of 0
and iteratively add to that base value to sum a list of numbers.</p>
<pre class="highlight"><code class="hljs coffeescript"><span class="hljs-function">=&gt;</span> <span class="hljs-function"><span class="hljs-params">(reduce + <span class="hljs-number">0</span> [<span class="hljs-number">1</span> <span class="hljs-number">2</span> <span class="hljs-number">3</span> <span class="hljs-number">4</span> <span class="hljs-number">5</span>])</span>
=&gt;</span> <span class="hljs-function"><span class="hljs-params">(reduce + <span class="hljs-number">1</span> [<span class="hljs-number">2</span> <span class="hljs-number">3</span> <span class="hljs-number">4</span> <span class="hljs-number">5</span>])</span>
=&gt;</span> <span class="hljs-function"><span class="hljs-params">(reduce + <span class="hljs-number">3</span> [<span class="hljs-number">3</span> <span class="hljs-number">4</span> <span class="hljs-number">5</span>])</span>
=&gt;</span> <span class="hljs-function"><span class="hljs-params">(reduce + <span class="hljs-number">6</span> [<span class="hljs-number">4</span> <span class="hljs-number">5</span>])</span>
=&gt;</span> (reduce + <span class="hljs-number">10</span> [<span class="hljs-number">5</span>])
<span class="hljs-number">15</span>
</code></pre><p>An interesting feature of both map and reduce is that they can be lazily
evaluated -- meaning that each operation can be performed only when it is
needed. With MapReduce, lazy evaluation allows you to work with large datasets
by processing data only when needed. </p>
<h2 id="mapreduce-stages">MapReduce Stages</h2>
<p>The App Engine MapReduce API provides a method for operating over large datasets
via a parallel and distributed system of lazy evaluation. In contrast to the
<code>map</code> and <code>reduce</code> functions a MapReduce job may output a single value or a list
of values depending on the job requirements. </p>
<p>A MapReduce job is made up of stages. Each stage completes before the next stage
begins and any intermediate data is stored in temporary storage between the
stages. MapReduce has three stages: map, shuffle and reduce.</p>
<h3 id="map">Map</h3>
<p>The map stage has two components -- an <em>InputReader</em> and a <em>map</em> function. The
InputReader&#39;s job is to deliver data one record at a time to the <em>map</em> function.
The <em>map</em> function is applied to each record individually and a key-value pair
is emitted. The data emitted by the <em>map</em> function is stored in temporary
storage for processing by the next stage.</p>
<p>The prototypical MapReduce example counts the number of each words in a set of
documents. For example, assume the input is a document database containing a
document id and the text of that document.</p>
<pre class="highlight"><code class="hljs livecodeserver"><span class="hljs-number">14877</span> DIY Pinterest narwhal forage typewriter, quinoa Odd Future. Fap hashtag 
<span class="hljs-number">88390</span> chillwave, paleo <span class="hljs-built_in">post</span>-ironic squid fanny pack yr PBR&amp;B High Life. Put <span class="hljs-operator">a</span> bird <span class="hljs-command"><span class="hljs-keyword">on</span> <span class="hljs-title">it</span></span>
<span class="hljs-number">73205</span> gastropub leggings ennui PBR&amp;B. Vice Pinterest <span class="hljs-number">8</span>-bit chambray. Dreamcatcher
<span class="hljs-number">95782</span> letterpress <span class="hljs-number">3</span> wolf moon, mustache craft beer Pitchfork yr trust fund Tonx <span class="hljs-number">77865</span> collie lassie
<span class="hljs-number">75093</span> Portland skateboard bespoke kitsch. Seitan irony mustache messenger bag,
<span class="hljs-number">24798</span> skateboard hashtag pickled tote bag <span class="hljs-keyword">try</span>-hard meggings actually Vice quinoa
<span class="hljs-number">13334</span> plaid. Biodiesel Echo Park fashion axe direct trade, forage Neutra <span class="hljs-keyword">try</span>-hard
</code></pre><p>Using the App Engine MapReduce API we can define a map function to output a
key-value pair for each occurrence of a word in the document.</p>
<pre class="highlight"><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">map</span><span class="hljs-params">(document)</span>:</span>
    <span class="hljs-string">"""
    Count the occurrence of each word in a document.
    """</span>
    <span class="hljs-keyword">for</span> word <span class="hljs-keyword">in</span> document:
        <span class="hljs-keyword">yield</span> (word.lower(), <span class="hljs-number">1</span>)
</code></pre>
<p>Our output would record each time a word was encountered within a document.</p>
<pre class="highlight"><code class="hljs r">diy <span class="hljs-number">1</span>
pinterest <span class="hljs-number">1</span>
narwhal <span class="hljs-number">1</span>
forage <span class="hljs-number">1</span>
typewriter <span class="hljs-number">1</span>
quinoa <span class="hljs-number">1</span>
odd <span class="hljs-number">1</span>
future <span class="hljs-number">1</span>
<span class="hljs-keyword">...</span> more records <span class="hljs-keyword">...</span>
pinterest <span class="hljs-number">1</span>
forage <span class="hljs-number">1</span>
quinoa <span class="hljs-number">1</span>
</code></pre><h3 id="shuffle">Shuffle</h3>
<p>The shuffle stage is done in two steps. First, the data emitted by the map stage
is sorted. Entries with the same key are grouped together. </p>
<pre class="highlight"><code class="hljs clojure"><span class="hljs-list">(<span class="hljs-title">diy</span>,<span class="hljs-number"> 1</span>)</span>
<span class="hljs-list">(<span class="hljs-title">forage</span>,<span class="hljs-number"> 1</span>)</span>
<span class="hljs-list">(<span class="hljs-title">forage</span>,<span class="hljs-number"> 1</span>)</span>
<span class="hljs-list">(<span class="hljs-title"><span class="hljs-built_in">future</span></span>,<span class="hljs-number"> 1</span>)</span>
<span class="hljs-list">(<span class="hljs-title">narwhal</span>,<span class="hljs-number"> 1</span>)</span>
<span class="hljs-list">(<span class="hljs-title">odd</span>,<span class="hljs-number"> 1</span>)</span>
<span class="hljs-list">(<span class="hljs-title">pinterest</span>,<span class="hljs-number"> 1</span>)</span>
<span class="hljs-list">(<span class="hljs-title">pinterest</span>,<span class="hljs-number"> 1</span>)</span>
<span class="hljs-list">(<span class="hljs-title">quinoa</span>,<span class="hljs-number"> 1</span>)</span>
<span class="hljs-list">(<span class="hljs-title">quinoa</span>,<span class="hljs-number"> 1</span>)</span>
<span class="hljs-list">(<span class="hljs-title">typewriter</span>,<span class="hljs-number"> 1</span>)</span>
</code></pre><p>Second, entries for each key are condensed into a single list of values. These
values are stored in temporary storage for processing by the next stage.</p>
<pre class="highlight"><code class="hljs clojure"><span class="hljs-list">(<span class="hljs-title">diy</span>, <span class="hljs-collection">[1]</span>)</span>
<span class="hljs-list">(<span class="hljs-title">forage</span>, <span class="hljs-collection">[1,<span class="hljs-number"> 1</span>]</span>)</span>
<span class="hljs-list">(<span class="hljs-title"><span class="hljs-built_in">future</span></span>, <span class="hljs-collection">[1]</span>)</span>
<span class="hljs-list">(<span class="hljs-title">narwhal</span>, <span class="hljs-collection">[1]</span>)</span>
<span class="hljs-list">(<span class="hljs-title">odd</span>, <span class="hljs-collection">[1]</span>)</span>
<span class="hljs-list">(<span class="hljs-title">pinterest</span>, <span class="hljs-collection">[1,<span class="hljs-number"> 1</span>]</span>)</span>
<span class="hljs-list">(<span class="hljs-title">quinoa</span>, <span class="hljs-collection">[1,<span class="hljs-number"> 1</span>]</span>)</span>
<span class="hljs-list">(<span class="hljs-title">typewriter</span>, <span class="hljs-collection">[1]</span>)</span>
</code></pre><h3 id="reduce">Reduce</h3>
<p>The reduce stage has two components -- a <em>reduce</em> function and an
<em>OutputWriter</em>. The reduce function is called for each unique key in the
shuffled temporary data. The <em>reduce</em> function emits a final value based on its
input. To count the number of occurrences of a word our reduce function will
look like this.</p>
<pre class="highlight"><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">reduce</span><span class="hljs-params">(key, values)</span>:</span>
   <span class="hljs-string">"""
    Sum the list of values.
    """</span>
    <span class="hljs-keyword">yield</span> (key, sum(values))
</code></pre>
<p>Applying this reducing function to our data would give the following output.</p>
<pre class="highlight"><code class="hljs clojure"><span class="hljs-list">(<span class="hljs-title">diy</span>,<span class="hljs-number"> 1</span>)</span>
<span class="hljs-list">(<span class="hljs-title">forage</span>,<span class="hljs-number"> 2</span>)</span>
<span class="hljs-list">(<span class="hljs-title"><span class="hljs-built_in">future</span></span>,<span class="hljs-number"> 1</span>)</span>
<span class="hljs-list">(<span class="hljs-title">narwhal</span>,<span class="hljs-number"> 1</span>)</span>
<span class="hljs-list">(<span class="hljs-title">odd</span>,<span class="hljs-number"> 1</span>)</span>
<span class="hljs-list">(<span class="hljs-title">pinterest</span>,<span class="hljs-number"> 2</span>)</span>
<span class="hljs-list">(<span class="hljs-title">quinoa</span>,<span class="hljs-number"> 2</span>)</span>
<span class="hljs-list">(<span class="hljs-title">typewriter</span>,<span class="hljs-number"> 1</span>)</span>
</code></pre><p>This output is passed to the <em>OutputWriter</em> which writes the data to permanent storage.</p>
<h2 id="the-benefits-of-mapreduce">The Benefits of MapReduce</h2>
<p>MapReduce performs parallel and distributed operations by partitioning the data
to be processed both spatially and temporally. The spatial partitioning is done
via <em>sharding</em> while the temporal partitioning is done via <em>slicing</em>.</p>
<h3 id="sharding-parallel-processing">Sharding: Parallel Processing</h3>
<p>The input data is divided into multiple smaller datasets called <em>shards</em>. Each
of these shards are processed in parallel. A shard is processed by an individual
instance of the map function with its own input reader that feeds it data
reserved for this shard. Likewise for the reduce function.</p>
<p>The benefit of sharding is that each shard can be processed in parallel.</p>
<h3 id="slicing-fault-tolerance">Slicing: Fault Tolerance</h3>
<p>The data in a shard is processed sequentially. Each shard is assigned a task and
that task iterates over all data in the shard using an App Engine Task Queue.
When a task is run it iterates over as much data from the shard as it can in 15
seconds (configurable). After this time period expires a new slice is created
and the process repeats until all data in the shard has been processed.</p>
<p>The benefit of slicing is fault tolerance. If an error occurs during the run of
a slice, that particular slice can be run again without affecting the processing
of previous or subsequent slices.</p>
<h2 id="conclusions">Conclusions</h2>
<p>MapReduce provides a convenient programming model for operating on large
datasets. In our next article we look at how to use the Python MapReduce API for
App Engine to process entities from the datastore.</p>
]]></description>
            <link>http://sookocheff.com/posts/2014-04-15-app-engine-mapreduce-api-part-1-the-basics</link>
            <guid isPermaLink="true">http://sookocheff.com/posts/2014-04-15-app-engine-mapreduce-api-part-1-the-basics</guid>
            <dc:creator><![CDATA[Kevin Sookocheff]]></dc:creator>
            <pubDate>Tue, 15 Apr 2014 18:09:36 GMT</pubDate>
        </item>
        <item>
            <title><![CDATA[Understanding JSON Patch]]></title>
            <description><![CDATA[<p>The typical update cycle for an API resource is to (1) GET the representation, (2) modify it and (3) PUT back the entire representation. This can waste bandwidth and processing time for large resources. An alternative is to use the <a href="https://tools.ietf.org/html/rfc5789">HTTP PATCH</a> extension method to only send the differences between two resources. HTTP PATCH applies a set of changes to the document referenced by the HTTP request.</p>
<pre class="highlight"><code class="hljs bash">PATCH /file.txt HTTP/<span class="hljs-number">1.1</span>
Host: sookocheff.com
Content-Type: application/json
If-Match: <span class="hljs-string">"e0036bbc6f"</span>

[description of changes]
</code></pre>
<p>The format of the PATCH request body differs depending on the representation of the resource. For JSON documents, <a href="https://tools.ietf.org/html/rfc6902">JSON Patch</a> defines this format.</p>
<p>A JSON Patch document is a sequential list of operations to be applied to an object. Each operation is a JSON object having exactly one <code>op</code> member.
Valid operations are <code>add</code>, <code>remove</code>, <code>replace</code>, <code>move</code>, <code>copy</code> and <code>test</code>. Any other operation is considered an error. </p>
<pre class="highlight"><code class="hljs json">{ "<span class="hljs-attribute">op</span>": <span class="hljs-value"><span class="hljs-string">"add"</span> </span>}
</code></pre>
<p>Each operation must also have exactly one <code>path</code> member. 
The <code>path</code> member is a <a href="https://tools.ietf.org/html/rfc6901">JSON Pointer</a> that determines a location within the JSON document to modify.</p>
<pre class="highlight"><code class="hljs json">{ "<span class="hljs-attribute">op</span>": <span class="hljs-value"><span class="hljs-string">"add"</span></span>, "<span class="hljs-attribute">path</span>": <span class="hljs-value"><span class="hljs-string">"/player/name"</span> </span>}
</code></pre>
<p>The remaining elements of a JSON Patch operation depend on the particular operation being performed.</p>
<h3 id="add">add</h3>
<p>The <code>add</code> operation is used in different ways depending on the target of the <code>path</code> being referenced. Generally speaking we can use <code>add</code> to append to a list, add a member to an object or update the value of an existing field. The <code>add</code> operation accepts a <code>value</code> member which is the value to update the referenced <code>path</code>. </p>
<h4 id="append-to-a-list">Append to a List</h4>
<p>To append a value to a list you use an existing list as the <code>path</code> of the operation. So, given the JSON document.</p>
<pre class="highlight"><code class="hljs bash">{
    <span class="hljs-string">"orders"</span>: [{<span class="hljs-string">"id"</span>: <span class="hljs-number">123</span>}, {<span class="hljs-string">"id"</span>: <span class="hljs-number">456</span>}]
}
</code></pre>
<p>We can append an order to the list using the <code>add</code> operation.</p>
<pre class="highlight"><code class="hljs bash">{ <span class="hljs-string">"op"</span>: <span class="hljs-string">"add"</span>, <span class="hljs-string">"path"</span>: <span class="hljs-string">"/orders"</span>, <span class="hljs-string">"value"</span>: {<span class="hljs-string">"id"</span>: <span class="hljs-number">789</span>} }
</code></pre>
<p>After applying the patch we get the final document.</p>
<pre class="highlight"><code class="hljs bash">{
    <span class="hljs-string">"orders"</span>: [{<span class="hljs-string">"id"</span>: <span class="hljs-number">123</span>}, {<span class="hljs-string">"id"</span>: <span class="hljs-number">456</span>}, {<span class="hljs-string">"id"</span>: <span class="hljs-number">789</span>}]
}
</code></pre>
<h4 id="add-a-member-to-an-object">Add a Member to an Object</h4>
<p>If the <code>path</code> references a member of an object that does not exist, a new member is added to the object. We start with our JSON document listing our orders.</p>
<pre class="highlight"><code class="hljs undefined">{
    "orders": [{"id": 123}, {"id": 456}, {"id": 789"}]
}
</code></pre>
<p>Using this JSON Patch document we can add a total and a currency member to the document.</p>
<pre class="highlight"><code class="hljs json">[
{ "<span class="hljs-attribute">op</span>": <span class="hljs-value"><span class="hljs-string">"add"</span></span>, "<span class="hljs-attribute">path</span>": <span class="hljs-value"><span class="hljs-string">"/total"</span></span>, "<span class="hljs-attribute">value</span>": <span class="hljs-value"><span class="hljs-number">20.00</span> </span>},
{ "<span class="hljs-attribute">op</span>": <span class="hljs-value"><span class="hljs-string">"add"</span></span>, "<span class="hljs-attribute">path</span>": <span class="hljs-value"><span class="hljs-string">"/currency"</span></span>, "<span class="hljs-attribute">value</span>": <span class="hljs-value"><span class="hljs-string">"USD"</span> </span>}
]
</code></pre>
<p>After applying the patch we get the final representation.</p>
<pre class="highlight"><code class="hljs json">{
    "<span class="hljs-attribute">orders</span>": <span class="hljs-value">[{"<span class="hljs-attribute">id</span>": <span class="hljs-value"><span class="hljs-number">123</span></span>}, {"<span class="hljs-attribute">id</span>": <span class="hljs-value"><span class="hljs-number">456</span></span>}, {"<span class="hljs-attribute">id</span>": <span class="hljs-value"><span class="hljs-number">789</span></span>}]</span>,
    "<span class="hljs-attribute">total</span>": <span class="hljs-value"><span class="hljs-number">20.00</span></span>,
    "<span class="hljs-attribute">currency</span>": <span class="hljs-value"><span class="hljs-string">"USD"</span>
</span>}
</code></pre>
<h4 id="update-an-existing-member-of-an-object">Update an Existing Member of an Object</h4>
<p>If the <code>path</code> refers to an existing object member, that member is updated with the newly supplied value.</p>
<p>Given the JSON document.</p>
<pre class="highlight"><code class="hljs json">{
    "<span class="hljs-attribute">orders</span>": <span class="hljs-value">[{"<span class="hljs-attribute">id</span>": <span class="hljs-value"><span class="hljs-number">123</span></span>}, {"<span class="hljs-attribute">id</span>": <span class="hljs-value"><span class="hljs-number">456</span></span>}, {"<span class="hljs-attribute">id</span>": <span class="hljs-value"><span class="hljs-number">789</span></span>}]</span>,
    "<span class="hljs-attribute">total</span>": <span class="hljs-value"><span class="hljs-number">20.00</span></span>,
    "<span class="hljs-attribute">currency</span>": <span class="hljs-value"><span class="hljs-string">"USD"</span>
</span>}
</code></pre>
<p>We can update the total by using an <code>add</code> operation.</p>
<pre class="highlight"><code class="hljs undefined">{ "op": "add", "path": "/total", "value": 30.00 },
</code></pre>
<p>Leaving the final result.</p>
<pre class="highlight"><code class="hljs json">{
    "<span class="hljs-attribute">orders</span>": <span class="hljs-value">[{"<span class="hljs-attribute">id</span>": <span class="hljs-value"><span class="hljs-number">123</span></span>}, {"<span class="hljs-attribute">id</span>": <span class="hljs-value"><span class="hljs-number">456</span></span>}, {"<span class="hljs-attribute">id</span>": <span class="hljs-value"><span class="hljs-number">789</span></span>}]</span>,
    "<span class="hljs-attribute">total</span>": <span class="hljs-value"><span class="hljs-number">30.00</span></span>,
    "<span class="hljs-attribute">currency</span>": <span class="hljs-value"><span class="hljs-string">"USD"</span>
</span>}
</code></pre>
<h3 id="remove">remove</h3>
<p>Remove is a simple operation. The target location of the <code>path</code> is removed from the object.</p>
<p>Starting with the following document.</p>
<pre class="highlight"><code class="hljs json">{
    "<span class="hljs-attribute">orders</span>": <span class="hljs-value">[{"<span class="hljs-attribute">id</span>": <span class="hljs-value"><span class="hljs-number">123</span></span>}, {"<span class="hljs-attribute">id</span>": <span class="hljs-value"><span class="hljs-number">456</span></span>}, {"<span class="hljs-attribute">id</span>": <span class="hljs-value"><span class="hljs-number">789</span></span>}]</span>,
    "<span class="hljs-attribute">total</span>": <span class="hljs-value"><span class="hljs-number">30.00</span></span>,
    "<span class="hljs-attribute">currency</span>": <span class="hljs-value"><span class="hljs-string">"USD"</span>
</span>}
</code></pre>
<p>We can remove the <code>currency</code> member with a <code>remove</code> operation.</p>
<pre class="highlight"><code class="hljs json">{ "<span class="hljs-attribute">op</span>": <span class="hljs-value"><span class="hljs-string">"remove"</span></span>, "<span class="hljs-attribute">path</span>": <span class="hljs-value"><span class="hljs-string">"/currency"</span> </span>}
</code></pre>
<pre class="highlight"><code class="hljs json">{
    "<span class="hljs-attribute">orders</span>": <span class="hljs-value">[{"<span class="hljs-attribute">id</span>": <span class="hljs-value"><span class="hljs-number">123</span></span>}, {"<span class="hljs-attribute">id</span>": <span class="hljs-value"><span class="hljs-number">456</span></span>}, {"<span class="hljs-attribute">id</span>": <span class="hljs-value"><span class="hljs-number">789</span></span>}]</span>,
    "<span class="hljs-attribute">total</span>": <span class="hljs-value"><span class="hljs-number">30.00</span>
</span>}
</code></pre>
<p>We can also remove an element from an array. All remaining elements are shifted one position to the left. To remove order <code>456</code> we can remove the array index referencing this order.</p>
<pre class="highlight"><code class="hljs json">{ "<span class="hljs-attribute">op</span>": <span class="hljs-value"><span class="hljs-string">"remove"</span></span>, "<span class="hljs-attribute">path</span>": <span class="hljs-value"><span class="hljs-string">"/orders/1"</span> </span>}
</code></pre>
<pre class="highlight"><code class="hljs json">{
    "<span class="hljs-attribute">orders</span>": <span class="hljs-value">[{"<span class="hljs-attribute">id</span>": <span class="hljs-value"><span class="hljs-number">123</span></span>}, {"<span class="hljs-attribute">id</span>": <span class="hljs-value"><span class="hljs-number">789</span></span>}]</span>,
    "<span class="hljs-attribute">total</span>": <span class="hljs-value"><span class="hljs-number">30.00</span>
</span>}
</code></pre>
<h3 id="replace">replace</h3>
<p>Replace is used to set a new value to a member of the object. It is logically equivalent to a <code>remove</code> operation followed by an <code>add</code> operation to the same <code>path</code> or to an <code>add</code> operation to an existing member. </p>
<p>Given the following JSON document.</p>
<pre class="highlight"><code class="hljs json">{
    "<span class="hljs-attribute">orders</span>": <span class="hljs-value">[{"<span class="hljs-attribute">id</span>": <span class="hljs-value"><span class="hljs-number">123</span></span>}, {"<span class="hljs-attribute">id</span>": <span class="hljs-value"><span class="hljs-number">456</span></span>}, {"<span class="hljs-attribute">id</span>": <span class="hljs-value"><span class="hljs-number">789</span></span>}]</span>,
    "<span class="hljs-attribute">total</span>": <span class="hljs-value"><span class="hljs-number">20.00</span></span>,
    "<span class="hljs-attribute">currency</span>": <span class="hljs-value"><span class="hljs-string">"USD"</span>
</span>}
</code></pre>
<p>We can apply the <code>replace</code> operation to update the order total.</p>
<pre class="highlight"><code class="hljs undefined">{ "op": "replace", "path": "/total", "value": 30.00 },
</code></pre>
<pre class="highlight"><code class="hljs json">{
    "<span class="hljs-attribute">orders</span>": <span class="hljs-value">[{"<span class="hljs-attribute">id</span>": <span class="hljs-value"><span class="hljs-number">123</span></span>}, {"<span class="hljs-attribute">id</span>": <span class="hljs-value"><span class="hljs-number">456</span></span>}, {"<span class="hljs-attribute">id</span>": <span class="hljs-value"><span class="hljs-number">789</span></span>}]</span>,
    "<span class="hljs-attribute">total</span>": <span class="hljs-value"><span class="hljs-number">30.00</span></span>,
    "<span class="hljs-attribute">currency</span>": <span class="hljs-value"><span class="hljs-string">"USD"</span>
</span>}
</code></pre>
<h3 id="move">move</h3>
<p> The <code>move</code> operation removes the value at a specified location and adds it to the target location. The removal location is given by a <code>from</code> member and the target location is given by the <code>path</code> member.</p>
<p>Given this starting document.</p>
<pre class="highlight"><code class="hljs json">{
    "<span class="hljs-attribute">orders</span>": <span class="hljs-value">[{"<span class="hljs-attribute">id</span>": <span class="hljs-value"><span class="hljs-number">123</span></span>}, {"<span class="hljs-attribute">id</span>": <span class="hljs-value"><span class="hljs-number">456</span></span>}, {"<span class="hljs-attribute">id</span>": <span class="hljs-value"><span class="hljs-number">789</span></span>}]</span>,
    "<span class="hljs-attribute">total</span>": <span class="hljs-value"><span class="hljs-number">30.00</span></span>,
    "<span class="hljs-attribute">currency</span>": <span class="hljs-value"><span class="hljs-string">"USD"</span>
</span>}
</code></pre>
<p>We can move an order to the root of the document by applying this JSON patch.</p>
<pre class="highlight"><code class="hljs bash">json
{ <span class="hljs-string">"op"</span>: <span class="hljs-string">"move"</span>, <span class="hljs-string">"from"</span>: <span class="hljs-string">"/orders/0"</span>, <span class="hljs-string">"path"</span>: <span class="hljs-string">"/rootOrder"</span> }
</code></pre><pre class="highlight"><code class="hljs json">{
    "<span class="hljs-attribute">orders</span>": <span class="hljs-value">[{"<span class="hljs-attribute">id</span>": <span class="hljs-value"><span class="hljs-number">456</span></span>}, {"<span class="hljs-attribute">id</span>": <span class="hljs-value"><span class="hljs-number">789</span></span>}]</span>,
    "<span class="hljs-attribute">rootOrder</span>": <span class="hljs-value">{"<span class="hljs-attribute">id</span>": <span class="hljs-value"><span class="hljs-number">123</span></span>}</span>, 
    "<span class="hljs-attribute">total</span>": <span class="hljs-value"><span class="hljs-number">30.00</span></span>,
    "<span class="hljs-attribute">currency</span>": <span class="hljs-value"><span class="hljs-string">"USD"</span>
</span>}
</code></pre>
<h3 id="copy">copy</h3>
<p><code>copy</code> is like <code>move</code>. It copies the value at the <code>from</code> location to the  <code>path</code> location, leaving duplicates of the data at each location.</p>
<pre class="highlight"><code class="hljs json">{ "<span class="hljs-attribute">op</span>": <span class="hljs-value"><span class="hljs-string">"copy"</span></span>, "<span class="hljs-attribute">from</span>": <span class="hljs-value"><span class="hljs-string">"/orders/0"</span></span>, "<span class="hljs-attribute">path</span>": <span class="hljs-value"><span class="hljs-string">"/rootOrder"</span> </span>}
</code></pre>
<h3 id="test">test</h3>
<p>The HTTP PATCH method is atomic and the patch should only be applied if all operations can be safely applied. The <code>test</code> operation can offer additional validation to ensure that patch preconditions or postconditions are met. If the test fails the whole patch is discarded. <code>test</code> is strictly an equality check.</p>
<pre class="highlight"><code class="hljs json">{ "<span class="hljs-attribute">op</span>": <span class="hljs-value"><span class="hljs-string">"test"</span></span>, "<span class="hljs-attribute">value</span>": <span class="hljs-value"><span class="hljs-number">30.00</span></span>, "<span class="hljs-attribute">path</span>": <span class="hljs-value"><span class="hljs-string">"/total"</span> </span>}
</code></pre>
<h3 id="conclusion">Conclusion</h3>
<p>JSON Patch is an effective way to provide diffs of your API resources. Most languages already have an implementation available. There is no reason not to adopt the HTTP PATCH today.</p>
]]></description>
            <link>http://sookocheff.com/posts/2014-04-08-understanding-json-patch</link>
            <guid isPermaLink="true">http://sookocheff.com/posts/2014-04-08-understanding-json-patch</guid>
            <dc:creator><![CDATA[Kevin Sookocheff]]></dc:creator>
            <pubDate>Tue, 08 Apr 2014 22:12:14 GMT</pubDate>
        </item>
        <item>
            <title><![CDATA[How to Version a REST API]]></title>
            <description><![CDATA[<p>API versioning is a fact of life. Even the most well designed API changes as new features and relationships are uncovered. Unfortunately, updating an API is seldom as simple as changing the behaviour of our existing URL endpoints on her he server. If we have existing clients we need to explicitly advertise breaking changes in a seamless way. This article explains a few methods of specifying breaking changes that offer a clear upgrade path for existing API clients. </p>
<h2 id="1-versioned-url">1) Versioned URL</h2>
<p>URL versioning inserts a version number directly in the URL of the resource. As an example,  version one of the API could be accessed through the <code>v1</code> URL.</p>
<pre class="highlight"><code class="hljs bash">http://sookocheff.com/api/v1/users/<span class="hljs-number">12345</span>
</code></pre>
<p>Version two of the API could be accessed through the <code>v2</code> URL. </p>
<pre class="highlight"><code class="hljs bash">http://sookocheff.com/api/v2/users/<span class="hljs-number">12345</span>
</code></pre>
<p>This solution has been widely adopted because it is easy to deploy and easy for client developers to understand. This method also makes each API version discoverable and browseable without using an advanced HTTP client  just alter the URL. </p>
<p>The drawback to using URL versioning is that by changing the URL of a resource with each new API version we are violating the REST constraint that <a href="http://sookocheff.com/posts/2014-03-19-how-rest-constraints-affect-api-design/">each resource be accessible via a unique URL</a>. To mitigate this you can map the current version of the API to a non-versioned URL.</p>
<pre class="highlight"><code class="hljs bash">http://sookocheff.com/api/users/
</code></pre>
<p>Once this mapping is in place you can safely deprecate old URLs by redirecting to the non-versioned URL -- notifying the client to use the latest version. At all times the non-versioned URL represents the latest version of that resource.</p>
<h3 id="pros-">Pros:</h3>
<ul>
<li>Easy to implement.</li>
<li>Easy to understand.</li>
<li>Direct path to deprecation.</li>
</ul>
<h3 id="cons-">Cons:</h3>
<ul>
<li>Violates REST principle of unique URLs for a resource.</li>
</ul>
<h2 id="2-versioned-media-type">2) Versioned Media Type</h2>
<p>When making an HTTP request the client can request a specific MIME type (or list of MIME types) that it is willing to accept using an <code>Accept</code> header. For example, an HTML client may use the following <code>Accept</code> header to request an HTML representation of the resource.</p>
<pre class="highlight"><code class="hljs http"><span class="hljs-request">GET <span class="hljs-string">/v1/users/12345</span> HTTP/1.1</span>
<span class="hljs-attribute">Host</span>: <span class="hljs-string">sookocheff.com</span>
<span class="hljs-attribute">Accept</span>: <span class="hljs-string">text/html</span>
</code></pre><p>Whereas an XML client may use the following <code>Accept</code> header to request an XML representation of the resource.</p>
<pre class="highlight"><code class="hljs http"><span class="hljs-request">GET <span class="hljs-string">/v1/users/12345</span> HTTP/1.1</span>
<span class="hljs-attribute">Host</span>: <span class="hljs-string">sookocheff.com</span>
<span class="hljs-attribute">Accept</span>: <span class="hljs-string">application/xml</span>
</code></pre><p>We can use this functionality to allow the client to access specific versions of a resource.</p>
<pre class="highlight"><code class="hljs http"><span class="hljs-request">GET <span class="hljs-string"></span> /users/12345 <span class="hljs-string">HTTP/1.1
Host:</span> sookocheff.com</span>
<span class="hljs-attribute">Accept</span>: <span class="hljs-string">application/vnd.sookocheff.user+json?version=2</span>
</code></pre><p>This method assumes we have defined a custom media type to represent every resource in our API and that the media type accepts a <code>version</code> parameter.</p>
<p>Versioning the media type does adhere to strict REST principles but causes problems in other ways. First, you need a custom media type for every resource returned by your API. This is not only reinventing the wheel -- <a href="http://schema.org/">perfectly good</a> <a href="http://www.iana.org/assignments/media-types/media-types.xhtml">media types</a> <a href="http://www.freeformatter.com/mime-types-list.html">already exist</a> -- it also creates a media type so specific to your API that it cannot be reused elsewhere. Lastly, it is unclear whether the version parameter applies to the version of the media type or to the version of your API.</p>
<h3 id="pros-">Pros:</h3>
<ul>
<li>Adheres to REST principles.</li>
</ul>
<h3 id="cons-">Cons:</h3>
<ul>
<li>Custom media type for every resource.</li>
<li>Binds your media type to your API.</li>
<li>Unclear versioning.</li>
<li>Requires sophisticated API client.</li>
</ul>
<h2 id="3-versioned-http-header">3) Versioned HTTP Header</h2>
<p>The <a href="http://www.w3.org/Protocols/rfc2616/rfc2616-sec7.html#sec7.1">HTTP specification</a> states that unknown HTTP headers MUST be forwarded on to the recipient. This means that custom HTTP headers can be set by our client and received by our API.</p>
<pre class="highlight"><code class="hljs bash">GET /users/<span class="hljs-number">12345</span> HTTP/<span class="hljs-number">1.1</span>
Host: sookocheff.com
Accept: application/json
Users-Version: <span class="hljs-number">2</span>
</code></pre>
<p>A server receiving this request can parse the header to ascertain the version number being requested by the client and return the proper representation. </p>
<p>This method requires that your API client is able to modify the HTTP headers of its requests. If the client is unable to provide a version number with the HTTP header you can assume that a request is made for the latest API version.</p>
<h3 id="pros-">Pros:</h3>
<ul>
<li>Adheres to REST principles.</li>
</ul>
<h3 id="cons-">Cons:</h3>
<ul>
<li>Requires sophisticated API client.</li>
</ul>
<h2 id="4-versioned-resources">4) Versioned Resources</h2>
<p>The last versioning method is to set the version number in the response itself. This places the burden of versioning with the client rather than the server. A client receiving a response from a known version number can parse it and act appropriately. It would be up to the client how to handle an unknown version number.</p>
<p>This method is only appropriate if you as the developer have direct control over both the server and the client being deployed.</p>
<h3 id="pros-">Pros:</h3>
<ul>
<li>Simplified server.</li>
</ul>
<h3 id="cons-">Cons:</h3>
<ul>
<li>Complex client.</li>
<li>Tightly couples server to client.</li>
</ul>
<h2 id="what-to-do-">What to do?</h2>
<p>By following <a href="http://sookocheff.com/posts/2014-03-19-how-rest-constraints-affect-api-design/">REST principles</a> we can guide our API versioning practices while being pragmatic about our choices so that our API can work in the real world.</p>
<p>My recommendation is to combine versioned URLs with custom HTTP headers using the following guidelines. With these guidelines we can safely version our API while supporting existing clients and offering them a clear upgrade path.</p>
<ol>
<li>Each major version of the API recieves a versioned URL.</li>
<li>One non-versioned URL always represents the latest API version. </li>
<li>Redirect deprecated URLs to the canonical URL after an advertised grace period.</li>
<li>Add a custom HTTP header for the version number.<ul>
<li>This header specifies both major <strong>and</strong> minor version numbers.</li>
<li>The non-versioned URL returns the appropriate version of the resource when specified by the HTTP header.</li>
</ul>
</li>
</ol>
<h2 id="references">References</h2>
<p><a href="http://www.vinaysahni.com/best-practices-for-a-pragmatic-restful-api">Vinay Sahni</a> has collected a long list of best practices for pragmatic API design, including versioning. </p>
<p><a href="http://stackoverflow.com/questions/389169/best-practices-for-api-versioning">stackoverflow</a> presents a collection of good answers providing best practices for API versioning.</p>
]]></description>
            <link>http://sookocheff.com/posts/2014-04-01-how-to-version-a-rest-api</link>
            <guid isPermaLink="true">http://sookocheff.com/posts/2014-04-01-how-to-version-a-rest-api</guid>
            <dc:creator><![CDATA[Kevin Sookocheff]]></dc:creator>
            <pubDate>Tue, 01 Apr 2014 20:16:18 GMT</pubDate>
        </item>
        <item>
            <title><![CDATA[When to Use HTTP PUT and HTTP POST]]></title>
            <description><![CDATA[<p>The HTTP protocol defines two methods for updating a resource -- <code>PUT</code> and
<code>POST</code>. Both <code>PUT</code> and <code>POST</code> are used to modify a resource and this semantic
similarity can confuse API developers. This confusion has led most developers to
use <code>POST</code> for any action which may modify the state of a resource, ignoring
<code>PUT</code> entirely.</p>
<p>This article attempts to explain the semantics behind the <code>PUT</code> and <code>POST</code>
methods and offers clear suggestions on when to use each method.</p>
<h2 id="put">PUT</h2>
<p>Let&#39;s go <a href="http://www.w3.org/Protocols/rfc2616/rfc2616.html">straight to the HTTP/1.1 RFC</a> for the <a href="http://www.w3.org/Protocols/rfc2616/rfc2616-sec9.html#sec9.6">definition of PUT</a>.</p>
<blockquote>
<p>The PUT method requests that the enclosed entity be stored under the supplied
Request-URI. If the Request-URI refers to an already existing resource, the
enclosed entity SHOULD be considered as a modified version of the one residing
on the origin server. If the Request-URI does not point to an existing
resource ... the origin server can create the resource with that URI.</p>
</blockquote>
<p>The PUT specification requires that you already know the URL of the resource you
wish to create or update. On create, if the client chooses the identifier for a
resource a PUT request will create the new resource at the specified URL.</p>
<pre class="highlight"><code class="hljs http"><span class="hljs-request">PUT <span class="hljs-string">/user/1234567890</span> HTTP/1.1</span>
<span class="hljs-attribute">Host</span>: <span class="hljs-string">http://sookocheff.com</span>

<span class="json">{
    "<span class="hljs-attribute">name</span>": <span class="hljs-value"><span class="hljs-string">"Kevin Sookocheff"</span></span>,
    "<span class="hljs-attribute">website</span>": <span class="hljs-value"><span class="hljs-string">"http://kevinsookocheff.com"</span>
</span>}
</span></code></pre><p>The server could respond with a <code>201 Created</code> status code and the new resource&#39;s
location.</p>
<pre class="highlight"><code class="hljs http"><span class="hljs-status">HTTP/1.1 <span class="hljs-number">201</span> Created</span>
<span class="hljs-attribute">Location</span>: <span class="hljs-string">/user/1234567890</span>
</code></pre><p>In addition, if you know that a resource already exists for a URL, you can make
a PUT request to that URL to replace the state of that resource on the server.
This example updates the user&#39;s website.</p>
<pre class="highlight"><code class="hljs http"><span class="hljs-request">PUT <span class="hljs-string">/user/1234567890</span> HTTP/1.1</span>
<span class="hljs-attribute">Host</span>: <span class="hljs-string">http://sookocheff.com</span>

<span class="json">{
    "<span class="hljs-attribute">name</span>": <span class="hljs-value"><span class="hljs-string">"Kevin Sookocheff"</span></span>,
    "<span class="hljs-attribute">website</span>": <span class="hljs-value"><span class="hljs-string">"http://sookocheff.com"</span>
</span>}
</span></code></pre><p>In general the HTTP PUT method replaces the resource at the current URL with the
resource contained within the request. PUT is used to both create and update the
state of a resource on the server. </p>
<h2 id="post">POST</h2>
<p>Let&#39;s go <a href="http://www.w3.org/Protocols/rfc2616/rfc2616.html">back to the HTTP/1.1 RFC</a> for the <a href="http://www.w3.org/Protocols/rfc2616/rfc2616-sec9.html#sec9.5">definition of POST</a>.</p>
<blockquote>
<p>The POST method is used to request that the origin server accept the entity
enclosed in the request as a new subordinate of the resource identified by the
Request-URI ...  The posted entity is subordinate to that URI in the same way
that a file is subordinate to a directory containing it, a news article is
subordinate to a newsgroup to which it is posted, or a record is subordinate
to a database.</p>
</blockquote>
<p>Practically speaking, POST is used to append a resource to an existing
collection. In the following example you do not know the actual URL of the
resource -- the server decides the location where it is stored under the
<code>user</code> collection. </p>
<pre class="highlight"><code class="hljs http"><span class="hljs-request">POST <span class="hljs-string">/user</span> HTTP/1.1</span>
<span class="hljs-attribute">Host</span>: <span class="hljs-string">http://sookocheff.com</span>

<span class="json">{
    "<span class="hljs-attribute">name</span>": <span class="hljs-value"><span class="hljs-string">"Bryan Larson"</span></span>,
    "<span class="hljs-attribute">website</span>": <span class="hljs-value"><span class="hljs-string">"http://www.bryanlarson.ca"</span>
</span>}
</span></code></pre><p>The server could respond with a <code>201 Created</code> status code and the resource&#39;s new
location.</p>
<pre class="highlight"><code class="hljs http"><span class="hljs-status">HTTP/1.1 <span class="hljs-number">201</span> Created</span>
<span class="hljs-attribute">Location</span>: <span class="hljs-string">/user/636363</span>
</code></pre><p>Subsequent updates to this user would be made through a <code>PUT</code> request to the
specific URL for the user - <code>/user/636363</code>.</p>
<p>The book <a href="http://www.amazon.ca/RESTful-Web-APIs-Leonard-Richardson/dp/1449358063">RESTful Web APIs</a>
classify this behaviour <em>POST-to-append</em> and is the generally recommended way to
handle a POST request within the context of a specific resource.</p>
<h2 id="putting-it-together">Putting it Together</h2>
<p>The <a href="http://www.w3.org/Protocols/rfc2616/rfc2616.html">HTTP/1.1 RFC</a> offers some guidance on <a href="http://www.w3.org/Protocols/rfc2616/rfc2616-sec9.html#sec9.6">distinguishing between POST and
PUT</a>.</p>
<blockquote>
<p>The fundamental difference between the POST and PUT requests is reflected in
the different meaning of the Request-URI. The URI in a POST request identifies
the resource that will handle the enclosed entity ...  In contrast, the URI in
a PUT request identifies the entity enclosed with the request.</p>
</blockquote>
<p>By following the existing semantics of the HTTP PUT and POST methods we can
begin to take advantage of the <a href="http://sookocheff.com/posts/2014-03-19-how-rest-constraints-affect-api-design/">benefits of REST</a> to write scalable and
robust APIs. Not only is your API ready to scale and easy to maintain, it is
easy to understand and use. By consistently following these existing semantics
you can avoid inserting special cases and &#39;gotchas&#39; into your API that confuse
client developers.</p>
]]></description>
            <link>http://sookocheff.com/posts/2014-03-27-when-to-use-http-put-and-http-post</link>
            <guid isPermaLink="true">http://sookocheff.com/posts/2014-03-27-when-to-use-http-put-and-http-post</guid>
            <dc:creator><![CDATA[Kevin Sookocheff]]></dc:creator>
            <pubDate>Thu, 27 Mar 2014 13:23:34 GMT</pubDate>
        </item>
    </channel>
</rss>