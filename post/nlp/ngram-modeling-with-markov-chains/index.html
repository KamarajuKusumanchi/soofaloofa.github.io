<!DOCTYPE html>
<html lang="en">
<head>

<title>N-gram Modeling With Markov Chains : sookocheff.com</title>

<meta charset="utf-8">
<meta http-equiv="content-type", content="text/html; charset=utf-8">
<meta name="viewport", content="width=device-width, initial-scale=1.0">

<link rel="canonical" href="http://sookocheff.com/post/nlp/ngram-modeling-with-markov-chains/">

<link rel="stylesheet" href="//netdna.bootstrapcdn.com/font-awesome/4.0.3/css/font-awesome.css">
<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Bree+Serif">
<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Open+Sans">
<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/8.6/styles/default.min.css">

<link rel="stylesheet" href="/css/vendor/bootstrap.min.css">
<link rel="stylesheet" href="/css/vendor/monokai_sublime.css">
<link rel="stylesheet" href="/css/style.css">

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-20611089-6', 'sookocheff.com');
  ga('send', 'pageview');
</script>




</head>
<body>

<div class="navbar navbar-default" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" data-toggle="collapse" data-target=".navbar-collapse" class="navbar-toggle">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a href="/" class="navbar-brand">Kevin Sookocheff</a>
    </div>
    <div class="navbar-collapse collapse">
      <ul class="nav navbar-nav navbar-right">
        <li>
          <a href="/project/">Projects</a>
        </li>
        <li class="">
          <a href="/post/">Posts</a>
        </li>
        <li class="dropdown">
          <a href="#" data-toggle="dropdown" class="dropdown-toggle">
            Subscribe <b class="caret"></b>
          </a>
          <ul class="dropdown-menu">
            <li><a href="http://eepurl.com/KJE01">Email</a></li>
            <li><a href="http://sookocheff.com/index.xml">RSS</a></li>
          </ul>
        </li>
      </ul>
    </div>
  </div>
</div>


<div class="container page-container">
  <div class="row">
    <div class="col-md-8 col-md-offset-2">
      <section class="page">
        <article class="post">
          <h1>N-gram Modeling With Markov Chains</h1>
          <p>
            <small class="text-muted">
              Posted on Friday, July 31, 2015 Â· <a href="http://sookocheff.com/post/nlp/ngram-modeling-with-markov-chains/#disqus_thread">0 Comments</a>
            </small>
          </p>

          <div class=".post-content">
            

<p>A common method of reducing the complexity of n-gram modeling is using the
<a href="https://en.wikipedia.org/wiki/Markov_property">Markov Property</a>. The Markov
Property states that the probability of future states depends only on the
present state, not on the sequence of events that preceded it. This concept can
be elegantly implemented using a <a href="https://en.wikipedia.org/wiki/Markov_chain">Markov
Chain</a> storing the probabilities of
transitioning to a next state.</p>

<p>Let&rsquo;s look at a simple example of a Markov Chain that models text using bigrams.
The following code creates a list of bigrams from a piece of text.</p>

<pre><code class="language-python">&gt;&gt;&gt; s = &quot;I am Sam. Sam I am. I do not like green eggs and ham.&quot;
&gt;&gt;&gt; tokens = s.split(&quot; &quot;)
&gt;&gt;&gt; bigrams = [(tokens[i],tokens[i+1]) for i in range(0,len(tokens)-1)]
&gt;&gt;&gt; bigrams
[('I', 'am'), ('am', 'Sam.'), ('Sam.', 'Sam'), ('Sam', 'I'), ('I', 'am.'), ('am.', 'I'), ('I', 'do'), ('do', 'not'), ('not', 'like'), ('like', 'green'), ('green', 'eggs'), ('eggs', 'and'), ('and', 'ham.')]
</code></pre>

<p>Listing the bigrams starting with the word <code>I</code> results in:
<code>I am</code>, <code>I am.</code>, and <code>I do</code>. If we were to use this data to predict a word that
follows the word <code>I</code> we have three choices and each of them has the same
probability (<sup>1</sup>&frasl;<sub>3</sub>) of being a valid choice. Modeling this using a Markov Chain
results in a state machine with an approximately 0.33 chance of transitioning to
any one of the next states.</p>

<p><a class="thumbnail" href="/img/nlp/ngram-modeling-with-markov-chains/transitions-from-I.png">
  <img src="/img/nlp/ngram-modeling-with-markov-chains/transitions-from-I.png" alt="Transitions from I">
</a>
</p>

<p>We can add additional transitions to our Chain by considering additional bigrams
starting with <code>am</code>, <code>am.</code>, and <code>do</code>. In each case, there is only one possible
choice for the next state in our Markov Chain given the bigrams we know from our
input text. Each transition from one of these states therefore has a 1.0
probability.</p>

<p><a class="thumbnail" href="/img/nlp/ngram-modeling-with-markov-chains/following-transitions-from-I.png">
  <img src="/img/nlp/ngram-modeling-with-markov-chains/following-transitions-from-I.png" alt="Following Transitions from I">
</a>
</p>

<p>Now, given a starting point in our chain, say <code>I</code>, we can follow the transitions
to predict a sequence of words. This sequence follows the probability
distribution of the bigrams we have learned. For example, we can randomly sample
from the possible transitions from <code>I</code> to arrive at the next possible state in
the machine.</p>

<pre><code class="language-python">&gt;&gt;&gt; import random
&gt;&gt;&gt; random.sample(['am', 'am.', 'do'], 1)
['am.']
&gt;&gt;&gt; random.sample(['am', 'am.', 'do'], 1)
['do']
</code></pre>

<p>Making the first transition, to <code>do</code>, we can sample from the possible states
following <code>do</code>.</p>

<pre><code class="language-python">&gt;&gt;&gt; random.sample(['am', 'am.', 'do'], 1)
['do']
</code></pre>

<h2 id="writing-a-markov-chain:d97a8c10263ba1350fa7aeccc4b468c0">Writing a Markov Chain</h2>

<p>We have all the building blocks we need to write a complete Markov Chain
implementation. The implementation is a simple dictionary with each key being
the current state and the value being the list of possible next states. For
example, after learning the text <code>I am Sam.</code> our dictionary would look like
this.</p>

<pre><code class="language-python">{
    'I': ['am'],
    'am': ['Sam.'],
}
</code></pre>

<p>And after adding the text <code>Sam I am.</code> our dictionary would look like this.</p>

<pre><code class="language-python">{
    'I': ['am', 'am.'],
    'am': ['Sam.'],
    'Sam': ['I'],
}
</code></pre>

<p>We can implement a basic Markov Chain that creates a bigram dictionary using the
following code.</p>

<pre><code class="language-python">class MarkovChain:

    def __init__(self):
        self.memory = {}

    def _learn_key(self, key, value):
        if key not in self.memory:
            self.memory[key] = []

        self.memory[key].append(value)

    def learn(self, text):
        tokens = text.split(&quot; &quot;)
        bigrams = [(tokens[i], tokens[i + 1]) for i in range(0, len(tokens) - 1)]
        for bigram in bigrams:
            self._learn_key(bigram[0], bigram[1])


if __name__ == '__main__':
    m = MarkovChain()
    m.learn('I am Sam. Sam I am. I do not like green eggs and ham.')
    print(m.memory)
</code></pre>

<pre><code class="language-python">&gt;&gt;&gt; python markov_chain.py
{'I': ['am', 'am.', 'do'],
 'Sam': ['I'],
 'Sam.': ['Sam'],
 'am': ['Sam.'],
 'am.': ['I'],
 'and': ['ham.'],
 'do': ['not'],
 'eggs': ['and'],
 'green': ['eggs'],
 'like': ['green'],
 'not': ['like']}
</code></pre>

<p>We can then transition to a new state in our Markov Chain by randomly
choosing a next state given the current state. If we do not have any information
on the current state we can randomly pick a state to start in.</p>

<pre><code class="language-python">def _next(self, current_state):
    next_possible = self.memory.get(current_state)

    if not next_possible:
        next_possible = self.memory.keys()

    return random.sample(next_possible, 1)
</code></pre>

<p>The transition probabilities between states naturally become weighted as we
learn more text.  For example, in the following sequence we learn a few
sentences with the same bigrams and in the final state we are twice as likely to
choose <code>am</code> as the next word following <code>I</code> by randomly sampling from the next
possible states.</p>

<pre><code class="language-python">&gt;&gt;&gt; from markov_chain import MarkovChain
&gt;&gt;&gt; m = MarkovChain()
&gt;&gt;&gt; m.learn('I am Sam.')
&gt;&gt;&gt; m.memory
{'I': ['am'], 'am': ['Sam.']}
&gt;&gt;&gt; m.learn('I am Kevin.')
&gt;&gt;&gt; m.memory
{'I': ['am', 'am'], 'am': ['Sam.', 'Kevin.']}
&gt;&gt;&gt; m.learn('I do.')
&gt;&gt;&gt; m.memory  # Twice as likely to follow 'I' with 'am' than 'do'.
{'I': ['am', 'am', 'do'], 'am': ['Sam.', 'Kevin.']}
</code></pre>

<p>The state machine produced by our code would have the probabilities in the
following figure.</p>

<p><a class="thumbnail" href="/img/nlp/ngram-modeling-with-markov-chains/learned-probabilities.png">
  <img src="/img/nlp/ngram-modeling-with-markov-chains/learned-probabilities.png" alt="Learned Probabilities">
</a>
</p>

<p>Finally, we can ask our chain to print out some text of an arbitrary length by
following the transitions between the text we have learned.</p>

<pre><code class="language-python">def babble(self, amount, state=''):
    if not amount:
        return state

    next_word = self._next(state)

    if not next_word:
        return state

    return state + ' ' + self.babble(amount - 1, next_word)
</code></pre>

<p>Putting it all together we have a simple Markov Chain that can learn bigrams and
babble text given the probability of bigrams that it has learned. Markov Chain&rsquo;s
are a simple way to store and query n-gram probabilities. Full source code for
this example follows.</p>

<h2 id="the-implementation:d97a8c10263ba1350fa7aeccc4b468c0">The Implementation</h2>

<pre><code class="language-python">import random


class MarkovChain:

    def __init__(self):
        self.memory = {}

    def _learn_key(self, key, value):
        if key not in self.memory:
            self.memory[key] = []

        self.memory[key].append(value)

    def learn(self, text):
        tokens = text.split(&quot; &quot;)
        bigrams = [(tokens[i], tokens[i + 1]) for i in range(0, len(tokens) - 1)]
        for bigram in bigrams:
            self._learn_key(bigram[0], bigram[1])

    def _next(self, current_state):
        next_possible = self.memory.get(current_state)

        if not next_possible:
            next_possible = self.memory.keys()

        return random.sample(next_possible, 1)[0]

    def babble(self, amount, state=''):
        if not amount:
            return state

        next_word = self._next(state)
        return state + ' ' + self.babble(amount - 1, next_word)
</code></pre>
 
          </div>

          <hr>
            <ul class="list-inline">
  <li>Share this post:</li>
  <li>
    <a href="https://twitter.com/intent/tweet?url=http%3a%2f%2fsookocheff.com%2fpost%2fnlp%2fngram-modeling-with-markov-chains%2f&text=N-gram%20Modeling%20With%20Markov%20Chains&via=soofaloofa">
      <i class="fa fa-twitter fa-lg"></i>
    </a>
  </li>
  <li>
    <a href="https://facebook.com/sharer.php?u=http%3a%2f%2fsookocheff.com%2fpost%2fnlp%2fngram-modeling-with-markov-chains%2f">
      <i class="fa fa-facebook fa-lg"></i>
    </a>
  </li>
  <li>
    <a href="https://plus.google.com/share?url=http%3a%2f%2fsookocheff.com%2fpost%2fnlp%2fngram-modeling-with-markov-chains%2f">
      <i class="fa fa-google-plus fa-lg"></i>
    </a>
  </li>
  <li>
    <a href="http://www.linkedin.com/shareArticle?mini=true&url=http%3a%2f%2fsookocheff.com%2fpost%2fnlp%2fngram-modeling-with-markov-chains%2f">
      <i class="fa fa-linkedin fa-lg"></i>
    </a>
  </li>
  <li>
    <a href="mailto:?subject=Check out this link&body=http%3a%2f%2fsookocheff.com%2fpost%2fnlp%2fngram-modeling-with-markov-chains%2f">
      <i class="fa fa-envelope fa-lg"></i>
    </a>
  </li>
</ul>

          <hr>

          <div class="donation">
            <p>Think this post was worth a dollar? If so, I'd love to have it. Support this site quickly and easily using the Paypal button below.</p>

            <div class="row">
              <div class="col-md-10 col-md-offset-5">
                <form action="https://www.paypal.com/cgi-bin/webscr" method="post" target="_top">
<input type="hidden" name="cmd" value="_s-xclick">
<input type="hidden" name="hosted_button_id" value="44DHX3GQMER48">
<table>
<tr><td><input type="hidden" name="on0" value="Amount of Support:">Amount of Support:</td></tr><tr><td><select name="os0">
	<option value="Hat Tip">Hat Tip $1.00 CAD</option>
	<option value="Coffee">Coffee $5.00 CAD</option>
	<option value="Beer">Beer $10.00 CAD</option>
	<option value="Lunch">Lunch $50.00 CAD</option>
	<option value="Dinner">Dinner $100.00 CAD</option>
</select> </td></tr>
</table>
<input type="hidden" name="currency_code" value="CAD">
<input type="image" src="https://www.paypalobjects.com/en_US/i/btn/btn_paynow_LG.gif" border="0" name="submit" alt="PayPal - The safer, easier way to pay online!">
<img alt="" border="0" src="https://www.paypalobjects.com/en_US/i/scr/pixel.gif" width="1" height="1">
</form>

              </div>
            </div>
          </div>

          <hr>

          <div class="blurb">
            <div class="row">
              <div class="col-md-10 col-md-offset-1">
                <h4 class="text-center">About Kevin Sookocheff</h4>
              </div>
            </div>

            <div class="row">
              <div class="col-md-4 col-md-offset-1">
                <p>
                  <img class="img-circle center-block" src="/img/profile.png">
                </p>
              </div>
              <div class="col-md-6">
                <p>
                  I am a Software Developer. I work at <a
  href="http://www.vendasta.com">VendAsta</a> with a bunch of great people. I
run a business as <a href="http://redfinchsoftware.com">Red Finch Software</a>.
You can find me online as <a
href="https://twitter.com/soofaloofa">soofaloofa</a>. I love to teach, learn,
speak, and write about business and software. 

                  <ul class="list-inline">
                    <li>On the web:</li>
                    <li><a href="http://www.twitter.com/soofaloofa"><i class="fa fa-twitter-square fa-lg"></i></a></li>
                    <li><a href="http://www.facebook.com/kevin.sookocheff"><i class="fa fa-facebook-square fa-lg"></i></a></li>
                    <li><a href="http://www.linkedin.com/in/kevinsookocheff"><i class="fa fa-linkedin-square fa-lg"></i></a></li>
                    <li><a href="https://github.com/soofaloofa"><i class="fa fa-github-square fa-lg"></i></a></li>
                    <li><a href="http://sookocheff.com/rss.xml"><i class="fa fa-rss-square fa-lg"></i></a></li>
                  </ul>
                </p>
              </div>
            </div>
          </div>
          <hr>

          <div id="disqus_thread"></div>
<script type="text/javascript">
     
    var disqus_shortname = 'kevinsookocheff'; 

     
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>

        </article>
      </section>
    </div>
  </div>
</div>

<footer>
 <div class="footer-above text-center">
   <div class="container">
     <div class="row">
       <div class="footer-col col-md-3">
         <h3>App Engine</h3>
         <ul class="list-unstyled">
           <li><a href="/series/mapreduce-api/">MapReduce API</a></li>
           <li><a href="/series/pipelines-api/">Pipelines API</a></li>
           <li><a href="/series/cloud-endpoints/">Cloud Endpoints</a></li>
         </ul>
       </div>

       <div class="footer-col col-md-3">
         <h3>APIs</h3>
         <ul class="list-unstyled">
           <li>
             <a href="/posts/2014-03-11-on-choosing-a-hypermedia-format/">On Choosing a Hypermedia Format</a>
           </li>
           <li>
             <a href="/posts/2014-03-27-when-to-use-http-put-and-http-post/">When to use HTTP PUT</a>
           </li>
         </ul>
       </div>

       <div class="footer-col col-md-3">
         <h3>Random</h3>
         <ul class="list-unstyled">
           <li>
           <a href="http://sookocheff.com/posts/2013-04-09-submitting-a-unity3d-game-to-the-mac-app-store/"> Unity3d on the Mac App Store</a>
           </li>
           <li>
             <a href="http://sookocheff.com/posts/2011-07-27-saving-canvas-data-to-an-image-file-with-javascript-and-php/">Saving Canvas Data to an Image</a>
           </li>
         </ul>
       </div>

       <div class="footer-col col-md-3">
         <h3>Social</h3>
         <ul class="list-unstyled">
           <li><a href="http://www.twitter.com/soofaloofa">Twitter</a></li>
           <li><a href="http://www.facebook.com/kevin.sookocheff">Facebook</a></li>
           <li><a href="http://www.linkedin.com/in/kevinsookocheff">LinkedIn</a></li>
           <li><a href="https://plus.google.com/+KevinSookocheff">Google+</a></li>
           <li><a href="https://github.com/soofaloofa">Github</a></li>
         </ul>
       </div>
     </div>
   </div>
 </div>
 <div class="footer-below text-center">
     <div class="container">
         <div class="row">
             <div class="col-lg-12">
                 &copy; Kevin Sookocheff Â· <a href="#">Top</a>
             </div>
         </div>
     </div>
 </div>
</footer>

<script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
<script src="//netdna.bootstrapcdn.com/bootstrap/3.1.1/js/bootstrap.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/8.6/highlight.min.js"></script>
<script src="/js/vendor/retina.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>
<script type="text/javascript">
 
var disqus_shortname = 'kevinsookocheff'; 

 
(function () {
var s = document.createElement('script'); s.async = true;
s.type = 'text/javascript';
s.src = 'http://' + disqus_shortname + '.disqus.com/count.js';
(document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
}());
</script>
</body>
</html>

