<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Kevin Sookocheff</title>
    <link>http://sookocheff.com/tags/ndb/</link>
    <language>en-us</language>
    <copyright>Copyright Kevin Sookocheff.</copyright>
    <lastBuildDate>Wed, 29 Apr 2015 06:19:23 CST</lastBuildDate>
    
    <item>
      <title>Durabledict for App Engine</title>
      <link>http://sookocheff.com/posts/2015-04-28-durabledict-for-app-engine/</link>
      <pubDate>Wed, 29 Apr 2015 06:19:23 CST</pubDate>
      <author>kevin.sookocheff@gmail.com (Kevin Sookocheff)</author>
      <guid>http://sookocheff.com/posts/2015-04-28-durabledict-for-app-engine/</guid>
      <description>

&lt;h2 id=&#34;tldr:46a321b74ae6cefada7eb3c5a5d8c50f&#34;&gt;tldr;&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/vendasta/datastoredict&#34;&gt;DatastoreDict&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;what-s-a-durabledict:46a321b74ae6cefada7eb3c5a5d8c50f&#34;&gt;What&amp;rsquo;s a durabledict?&lt;/h2&gt;

&lt;p&gt;Good question. &lt;a href=&#34;https://github.com/disqus/durabledict&#34;&gt;Durabledict&lt;/a&gt; is a Python
implementation of a persistent dictionary. The dictionary values are cached
locally and sync with the datastore whenever a value in the datastore changes.&lt;/p&gt;

&lt;p&gt;Disqus provides concrete implementations for Redis, Django, ZooKeeper and in
memory. This blog post details an implementation using the App Engine datastore
and memcache.&lt;/p&gt;

&lt;h2 id=&#34;creating-your-own-durabledict:46a321b74ae6cefada7eb3c5a5d8c50f&#34;&gt;Creating your own durabledict&lt;/h2&gt;

&lt;p&gt;By following the &lt;a href=&#34;https://github.com/disqus/durabledict&#34;&gt;guide the durabledict
README&lt;/a&gt; we can create our own
implementation. We need to subclass &lt;code&gt;durabledict.base.DurableDict&lt;/code&gt; and implement
the following interface methods. Strictly speaking, &lt;code&gt;_pop&lt;/code&gt; and &lt;code&gt;_setdefault&lt;/code&gt; do
not have to be implemented but doing so makes your durabledict behave like a
base dict in all cases.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;persist(key, value)&lt;/code&gt; - Persist value at key to your data store.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;depersist(key)&lt;/code&gt; - Delete the value at key from your data store.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;durables()&lt;/code&gt; - Return a key=val dict of all keys in your data store.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;last_updated()&lt;/code&gt; - A comparable value of when the data in your data store was last updated.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;_pop(key, default=None)&lt;/code&gt; - If key is in the dictionary, remove it and return its value, else return default. If default is not given and key is not in the dictionary, a KeyError is raised.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;_setdefault(key, default=None)&lt;/code&gt; - If key is in the dictionary, return its value. If not, insert key with a value of default and return default. default defaults to None.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s implement these one-by-one.&lt;/p&gt;

&lt;h3 id=&#34;persist-key-value:46a321b74ae6cefada7eb3c5a5d8c50f&#34;&gt;persist(key, value)&lt;/h3&gt;

&lt;p&gt;Persisting a value to the datastore is a relatively simple operation. If the key
already exists we update it&amp;rsquo;s value. If the key does not already exist we create
it. To aid with this operation we create a &lt;code&gt;get_or_create&lt;/code&gt; method that will
return an existing entity if one exists or create a new entity if one does not
exist.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def persist(self, key, val):
    instance, created = get_or_create(self.model, key, val)

    if not created and instance.value != val:
        instance.value = val
        instance.put()

    self.touch_last_updated()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The last line of this function updates the last time this durabledict was
changed. This is used for caching. We create the &lt;code&gt;last_updated&lt;/code&gt; and
&lt;code&gt;touch_last_updated&lt;/code&gt; functions now.&lt;/p&gt;

&lt;h3 id=&#34;last-updated-key-value:46a321b74ae6cefada7eb3c5a5d8c50f&#34;&gt;last_updated(key, value)&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def last_updated(self):
    return self.cache.get(self.cache_key)

def touch_last_updated(self):
    self.cache.incr(self.cache_key, initial_value=self.last_synced + 1)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;init:46a321b74ae6cefada7eb3c5a5d8c50f&#34;&gt;&lt;strong&gt;init&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;We now have the building blocks to create our initial durabledict. Within the
&lt;code&gt;__init__&lt;/code&gt; method we set a manager and cache instance. The manager is
responsible for ndb datastore operations to decouple the ndb interface from the
durabledict implementation. We decouple our caching method in a similar fashion.
We also set the initial value of the cache whenever we create a new instance of
the durabledict.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from google.appengine.api import memcache

from durabledict.base import DurableDict
from durabledict.encoding import NoOpEncoding


class DatastoreDict(DurableDict):

    def __init__(self,
                 model,
                 value_col=&#39;value&#39;,
                 cache=memcache,
                 cache_key=&#39;__DatastoreDict:LastUpdated__&#39;):

        self.model = model
        self.value_col = value_col
        self.cache = cache
        self.cache_key = cache_key

        self.cache.add(self.cache_key, 1)

        super(DatastoreDict, self).__init__(encoding=NoOpEncoding)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;depersist-key:46a321b74ae6cefada7eb3c5a5d8c50f&#34;&gt;depersist(key)&lt;/h3&gt;

&lt;p&gt;Depersist implies deleting a key from the dictionary (and datastore). Here we
assume a helper method &lt;code&gt;delete&lt;/code&gt; that, given an ndb model and a string
representing it&amp;rsquo;s key deletes the model. Since the data has changed we also
update the last touched value to force a cache invalidation and data refresh.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def depersist(self, key):
    delete(self.model, key)
    self.touch_last_updated()
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;durables:46a321b74ae6cefada7eb3c5a5d8c50f&#34;&gt;durables()&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;durables()&lt;/code&gt; returns the entire dictionary. Since we are all matching entities
from the datastore it is important to keep your dictionary relatively small &amp;ndash;
as the dictionary grows in size, resyncing it&amp;rsquo;s state with the datastore will
get more and more expensive. This function assumes a &lt;code&gt;get_all&lt;/code&gt; method that will
return all instances of a model.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def durables(self):
    encoded_models = get_all(self.model)
    return dict((model.key.id(), getattr(model, self.value_col)) for model in encoded_models)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;setdefault-key-default-none:46a321b74ae6cefada7eb3c5a5d8c50f&#34;&gt;setdefault(key, default=None)&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;_setdefault()&lt;/code&gt; overrides the dictionary built-in &lt;code&gt;setdefault&lt;/code&gt; which allows you
to insert a key into the dictionary, creating the key with the default value if
it does not exist and returning the existing value if it does exist.&lt;/p&gt;

&lt;p&gt;For example, the following sequence of code creates a key for &lt;code&gt;y&lt;/code&gt;, which does not
exist, and returns the existing value for &lt;code&gt;x&lt;/code&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;&amp;gt;&amp;gt;&amp;gt; d = {&#39;x&#39;: 1}
&amp;gt;&amp;gt;&amp;gt; d.setdefault(&#39;y&#39;, 2)
2
&amp;gt;&amp;gt;&amp;gt; d
{&#39;y&#39;: 2, &#39;x&#39;: 1}
&amp;gt;&amp;gt;&amp;gt; d.setdefault(&#39;x&#39;, 3)
1
&amp;gt;&amp;gt;&amp;gt; d
{&#39;y&#39;: 2, &#39;x&#39;: 1}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We can implement &lt;code&gt;_setdefault&lt;/code&gt; using the &lt;code&gt;get_or_create&lt;/code&gt; helper method, updating
the cache if we have changed the dictionary.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def _setdefault(self, key, default=None):
    instance, created = get_or_create(self.model, key, default)

    if created:
        self.touch_last_updated()

    return getattr(instance, self.value_col)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;pop-key-default-none:46a321b74ae6cefada7eb3c5a5d8c50f&#34;&gt;pop(key, default=None)&lt;/h3&gt;

&lt;p&gt;pop returns the value for a key and deletes the key. This is fairly straight
forward given a &lt;code&gt;get&lt;/code&gt; and &lt;code&gt;delete&lt;/code&gt; helper method.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def _pop(self, key, default=None):
    instance = get(self.model, key)
    if instance:
        value = getattr(instance, self.value_col)
        delete(self.model, key)
        self.touch_last_updated()
        return value
    else:
        if default is not None:
            return default
        else:
            raise KeyError
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;the-help:46a321b74ae6cefada7eb3c5a5d8c50f&#34;&gt;The Help&lt;/h3&gt;

&lt;p&gt;The previous discussion uses a few helper methods that we haven&amp;rsquo;t defined yet.
Each of these methods takes an arbitrary ndb model and performs an operation on
it.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def build_key(cls, key):
    return ndb.Key(DatastoreDictAncestorModel,
                   DatastoreDictAncestorModel.generate_key(cls).string_id(),
                   cls, key.lower(),
                   namespace=&#39;&#39;)


@ndb.transactional
def get_all(cls):
    return cls.query(
        ancestor=DatastoreDictAncestorModel.generate_key(cls)).fetch()


@ndb.transactional
def get(cls, key):
    return build_key(cls, key).get()


@ndb.transactional
def get_or_create(cls, key, value=None):
    key = build_key(cls, key)

    instance = key.get()
    if instance:
        return instance, False

    instance = cls(key=key, value=value)
    instance.put()

    return instance, True


@ndb.transactional
def delete(cls, key):
    key = build_key(cls, key)
    return key.delete()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The last item of note is the use of a parent for each DatastoreDict. This common
ancestor forces strong read consistency for the &lt;code&gt;get_all&lt;/code&gt; method, allowing us to
update a dictionary and have a consistent view of the data on subsequent reads.
We use an additional model to provide the strong read consistency.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;class DatastoreDictAncestorModel(ndb.Model):

    @classmethod
    def generate_key(cls, child_cls):
        key_name = &#39;__%s-%s__&#39; % (&#39;ancestor&#39;, child_cls.__name__)
        return ndb.Key(cls, key_name, namespace=&#39;&#39;)
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Composing Asynchronous Functions With Tasklets</title>
      <link>http://sookocheff.com/posts/2014-09-27-composing-asynchronous-functions-with-tasklets/</link>
      <pubDate>Sat, 27 Sep 2014 15:25:29 UTC</pubDate>
      <author>kevin.sookocheff@gmail.com (Kevin Sookocheff)</author>
      <guid>http://sookocheff.com/posts/2014-09-27-composing-asynchronous-functions-with-tasklets/</guid>
      <description>

&lt;p&gt;Asynchronous functions can provide a boon to application performance by allowing time consuming functions to operate in parallel and without blocking the main execution thread. This article explains how to use the Tasklet API to compose and execute asynchronous functions in Google App Engine.&lt;/p&gt;

&lt;h2 id=&#34;ndb-future:6fb5794bdb1524859157ecc223808a6d&#34;&gt;ndb.Future&lt;/h2&gt;

&lt;p&gt;A &lt;a href=&#34;https://developers.google.com/appengine/docs/python/ndb/futureclass&#34;&gt;Future&lt;/a&gt; is a class representing an asynchronous I/O operation. &lt;code&gt;ndb&lt;/code&gt; provides asynchronous versions of datastore operations that will return a future instead of immediately returning data.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;future = User.get_by_id_async(uid)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;When a Future is first created it has no data while the I/O operation is running. By calling &lt;code&gt;get_result()&lt;/code&gt; on the Future the application will stop execution of the current thread until the data is available from the I/O operation.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;future = User.get_by_id_async(uid)
user = future.get_result()  # Return the data, blocking execution until the data is ready.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The above code is equivalent to calling the non-asynchronous &lt;code&gt;ndb.get&lt;/code&gt; function.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;user = User.get_by_id(uid)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Using futures in this way allows you to run multiple I/O operations in parallel.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Run two asynchronous operations in parallel
user_future = User.get_by_id_async(uid)
accounts_future = Account.query(Account.user_id==uid).fetch_async()
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;ndb-tasklet:6fb5794bdb1524859157ecc223808a6d&#34;&gt;ndb.tasklet&lt;/h2&gt;

&lt;p&gt;Tasklets allow you to create your own asynchronous functions that return a Future. The application can call &lt;code&gt;get_result()&lt;/code&gt; on that Future to return the data.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;tasklet_future = my_tasklet()  # A tasklet
result = tasklet_future.get_result()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You can use Tasklets to create fine grained asynchronous functions, in some cases simplifying how a method is programmed.&lt;/p&gt;

&lt;p&gt;When AppEngine encounters a tasklet function the Tasklet framework inserts the tasklet into an event loop. The event loop will cycle through all tasklets and execute them until a &lt;code&gt;yield&lt;/code&gt; statement is reached within the tasklet. The &lt;code&gt;yield&lt;/code&gt; statement is where you put the asynchronous work so that the framework can execute your &lt;code&gt;yield&lt;/code&gt; statement (asynchronously) and then move on to another tasklet to resume execution until its &lt;code&gt;yield&lt;/code&gt; statement is reached. In this way all of the &lt;code&gt;yield&lt;/code&gt; statements are done asynchronously. For even more performance, NDB implements a batch job framework that will bundle up multiple requests in a single batch RPC to the server.&lt;/p&gt;

&lt;p&gt;As a simple example, we can use a tasklet to define an asynchronous query and return the result.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;@ndb.tasklet
def query_tasklet():
    result = yield Model.query().fetch_async()
    raise ndb.Return(result)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The line &lt;code&gt;result = yield Model.query().fetch_async()&lt;/code&gt; will alert the tasklet framework that this is an asynchronous line of code and that the framework can wait here and execute other code while the asynchronous line completes. To force the asynchronous code to complete you call &lt;code&gt;get_result()&lt;/code&gt; on the return value of the tasklet function.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;future = query_tasklet()
future.get_result()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;So how do we use this in our code? There are three distinct cases.&lt;/p&gt;

&lt;h2 id=&#34;case-1-processing-an-asynchronous-result:6fb5794bdb1524859157ecc223808a6d&#34;&gt;Case 1: Processing an asynchronous result&lt;/h2&gt;

&lt;p&gt;Suppose that you have an asynchronous function that returns a Future and you want to do some processing on the result before returning from your function. In that case you may have code like this.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def process_a_query():
	future = Model.query().fetch_async()
	return process_result(future.get_result())
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;To turn this into an asynchronous tasklet function you can add the tasklet decorator and yield your asynchronous fetch.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;@ndb.tasklet
def process_a_query():
	result = yield Model.query().fetch_async()
	raise ndb.Return(process_result(result))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now your function &lt;code&gt;process_a_query&lt;/code&gt; can be called asynchronously.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;future = process_a_query()
# ...
future.get_result()
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;case-2-composing-two-asynchronous-functions:6fb5794bdb1524859157ecc223808a6d&#34;&gt;Case 2: Composing two asynchronous functions&lt;/h2&gt;

&lt;p&gt;In this case, suppose you have two asynchronous functions that depend on each other and you want to combine them with the tasklet framework.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def multiple_query():
	future_a = ModelA.query().fetch_async()
	a = future_a.get_result()
	future_b = ModelB.query(ModelB.id==a).fetch_async()
	return future_b
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The above code becomes simpler with tasklets.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;@ndb.tasklet
def multiple_query():
    a = yield ModelA.query().fetch_async()
    b = yield ModelB.query(ModelB.id==a).fetch_async()
    raise ndb.Return(b)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;case-3-parallel-computation:6fb5794bdb1524859157ecc223808a6d&#34;&gt;Case 3: Parallel Computation&lt;/h2&gt;

&lt;p&gt;The last case to discuss is parallel computation. In this scenario you have two independent asynchronous functions that you want to run in parallel.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;@ndb.tasklet
def parallel_query():
	  a, b = yield ModelA.query().fetch_async(), yield ModelB.query().fetch_async()
	  raise ndb.Return((a,b))
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;summary:6fb5794bdb1524859157ecc223808a6d&#34;&gt;Summary&lt;/h2&gt;

&lt;p&gt;In all of these cases we show how to combine and compose asynchronous functions using the tasklet framework. This allows you to define your own asynchronous functions that are can be used just like the ndb asynchronous functions.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Converting an ndb model to a BigQuery schema</title>
      <link>http://sookocheff.com/posts/2014-08-14-converting-an-ndb-model-to-a-bigquery-schema/</link>
      <pubDate>Thu, 14 Aug 2014 17:58:03 UTC</pubDate>
      <author>kevin.sookocheff@gmail.com (Kevin Sookocheff)</author>
      <guid>http://sookocheff.com/posts/2014-08-14-converting-an-ndb-model-to-a-bigquery-schema/</guid>
      <description>

&lt;p&gt;I have been working on the problem of recording changes to an ndb model. One way to accomplish this is to stream data changes to a BigQuery table corresponding to the ndb model. It would be great to do this in a generic way which gives us the problem of generating a BigQuery table given an ndb model. This article will describe one solution to this problem.&lt;/p&gt;

&lt;h2 id=&#34;accessing-the-properties-of-an-ndb-class:8ea270a790f9e4ece9bbdae40a8382a6&#34;&gt;Accessing the properties of an ndb class&lt;/h2&gt;

&lt;p&gt;The first step in the process is to find all the properties of the class via the
ndb &lt;code&gt;_properties&lt;/code&gt; accessor. By iterating over this field we can find all of the
properties on the class and their ndb types.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def tablify(ndb_model):
    &amp;quot;&amp;quot;&amp;quot;
    Convert ndb_model into a BigQuery table schema.
    &amp;quot;&amp;quot;&amp;quot;
    for name, ndb_type in ndb_model.__class__._properties.iteritmes():
       print name, ndb_type
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;converting-properties-to-bigquery-schema-types:8ea270a790f9e4ece9bbdae40a8382a6&#34;&gt;Converting properties to BigQuery schema types&lt;/h2&gt;

&lt;p&gt;Now that we have the set of properties on the class we can map from the type of
each property to a BigQuery type. Here is a helper function that provides a
simple mapping.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def ndb_type_to_bigquery_type(_type):
    &amp;quot;&amp;quot;&amp;quot;
    Convert a python type to a bigquery type.
    &amp;quot;&amp;quot;&amp;quot;
    if isinstance(_type, ndb.IntegerProperty):
        return &amp;quot;INTEGER&amp;quot;
    elif isinstance(_type, ndb.FloatProperty):
        return &amp;quot;FLOAT&amp;quot;
    elif isinstance(_type, ndb.BooleanProperty):
        return &amp;quot;BOOLEAN&amp;quot;
    elif type(_type) in [ndb.StringProperty, ndb.TextProperty, ndb.ComputedProperty]:
        return &amp;quot;STRING&amp;quot;
    elif type(_type) in [ndb.DateTimeProperty, ndb.DateProperty, ndb.TimeProperty]:
        return &amp;quot;TIMESTAMP&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The last task is to format everything as a &lt;a href=&#34;https://developers.google.com/bigquery/docs/reference/v2/tables&#34;&gt;BigQuery table
resource&lt;/a&gt;. This
involves adding some boiler-plate around each field in our BigQuery schema and
fleshing out the structure of the JSON.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;
from google.appengine.ext import ndb

SUPPORTED_TYPES = [ndb.IntegerProperty,
                   ndb.FloatProperty,
                   ndb.BooleanProperty,
                   ndb.StringProperty,
                   ndb.TextProperty,
                   ndb.DateTimeProperty,
                   ndb.DateProperty,
                   ndb.TimeProperty,
                   ndb.ComputedProperty]


def ndb_type_to_bigquery_type(_type):
    &amp;quot;&amp;quot;&amp;quot;
    Convert a python type to a bigquery type.
    &amp;quot;&amp;quot;&amp;quot;
    if isinstance(_type, ndb.IntegerProperty):
        return &amp;quot;INTEGER&amp;quot;
    elif isinstance(_type, ndb.FloatProperty):
        return &amp;quot;FLOAT&amp;quot;
    elif isinstance(_type, ndb.BooleanProperty):
        return &amp;quot;BOOLEAN&amp;quot;
    elif type(_type) in [ndb.StringProperty, ndb.TextProperty, ndb.ComputedProperty]:
        return &amp;quot;STRING&amp;quot;
    elif type(_type) in [ndb.DateTimeProperty, ndb.DateProperty, ndb.TimeProperty]:
        return &amp;quot;TIMESTAMP&amp;quot;


def ndb_property_to_bigquery_field(name, ndb_type):
    &amp;quot;&amp;quot;&amp;quot;
    Convert from ndb property to a BigQuery schema table field.
    &amp;quot;&amp;quot;&amp;quot;
    if type(ndb_type) not in SUPPORTED_TYPES:
        raise ValueError(&#39;Unsupported object property&#39;)

    field = {
        &amp;quot;description&amp;quot;: name,
        &amp;quot;name&amp;quot;: name,
        &amp;quot;type&amp;quot;: ndb_type_to_bigquery_type(ndb_type)
    }

    if ndb_type._repeated:
        field[&#39;mode&#39;] = &#39;REPEATED&#39;

    return field


def tablify_schema(obj):
    &amp;quot;&amp;quot;&amp;quot;
    Convert ndb_model into a BigQuery table schema.
    &amp;quot;&amp;quot;&amp;quot;
    table_schema = {&#39;fields&#39;: []}
    
    for name, ndb_type in obj.__class__._properties.iteritems():
        table_schema[&#39;fields&#39;].append(ndb_property_to_bigquery_field(name, ndb_type))

    return table_schema


def tablify(obj, project_id, dataset_id, table_id):
    &amp;quot;&amp;quot;&amp;quot;
    Return a BigQuery table resource representing an ndb object.
    &amp;quot;&amp;quot;&amp;quot;
    return {
        &amp;quot;kind&amp;quot;: &amp;quot;bigquery#table&amp;quot;,
        &amp;quot;id&amp;quot;: table_id,
        &amp;quot;tableReference&amp;quot;: {
            &amp;quot;projectId&amp;quot;: project_id,
            &amp;quot;datasetId&amp;quot;: dataset_id,
            &amp;quot;tableId&amp;quot;: table_id
        },
        &amp;quot;description&amp;quot;: &amp;quot;Table Resource&amp;quot;,
        &amp;quot;schema&amp;quot;: tablify_schema(obj)
    }
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;creating-the-new-table-on-bigquery:8ea270a790f9e4ece9bbdae40a8382a6&#34;&gt;Creating the new table on BigQuery.&lt;/h2&gt;

&lt;p&gt;Now that we have a BigQuery schema we can create the table in BigQuery using the BigQuery api client.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from oauth2client.appengine import AppAssertionCredentials
from apiclient.discovery import build

credentials = AppAssertionCredentials(scope=&#39;https://www.googleapis.com/auth/bigquery&#39;)
http = credentials.authorize(httplib2.Http())
big_query_service = build(&#39;bigquery&#39;, &#39;v2&#39;, http=http)
        
table_resource = tablify(ndb_model, project_id, dataset_id, table_id)
                response = big_query_service.tables().insert(projectId=project_id,
                                                             datasetId=dataset_id,
                                                             body=table_resource).execute()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And that&amp;rsquo;s it. This article outlined a quick method of generating a BigQuery
table scheme from an ndb model. If you found this useful let me know in the
comments.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Bypassing ndb hooks with the RawDatastoreInputReader</title>
      <link>http://sookocheff.com/posts/2014-07-29-bypassing-ndb-hooks-with-the-raw-datastore-input-reader/</link>
      <pubDate>Tue, 29 Jul 2014 20:32:42 UTC</pubDate>
      <author>kevin.sookocheff@gmail.com (Kevin Sookocheff)</author>
      <guid>http://sookocheff.com/posts/2014-07-29-bypassing-ndb-hooks-with-the-raw-datastore-input-reader/</guid>
      <description>

&lt;p&gt;When doing a MapReduce operation there are times when you want to edit a set of
entities without triggering the post or pre put hooks associated with those
entities. On such ocassions using the raw datastore entity allows you to process
the data without unwanted side effects. This article will show how to use the
RawDatastoreInputReader to process datastore entities.&lt;/p&gt;

&lt;p&gt;When doing a MapReduce operation there are times when you want to edit a set of entities without triggering the post or pre put hooks associated with those entities. On such ocassions using the raw datastore entity allows you to process the data without unwanted side effects.&lt;/p&gt;

&lt;p&gt;For the sake of this discussion let&amp;rsquo;s assume we want to move a &lt;code&gt;phone_number&lt;/code&gt; field to a &lt;code&gt;work_number&lt;/code&gt; field for all entities of a certain Kind in the datastore.&lt;/p&gt;

&lt;h2 id=&#34;getting-the-raw-datastore-entity:f509f31b4c10397cd1059cd7982b595f&#34;&gt;Getting the raw datastore entity&lt;/h2&gt;

&lt;p&gt;The MapReduce library provides a &lt;code&gt;RawDatastoreInputReader&lt;/code&gt; that will feed raw datastore entities to your mapping function. We can set our MapReduce operation to use the &lt;code&gt;RawDatastoreInputReader&lt;/code&gt; using a &lt;code&gt;mapreduce.yaml&lt;/code&gt; declaration.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;- name: move_phone_numbers
  mapper:
    input_reader: mapreduce.input_readers.RawDatastoreInputReader
    handler: app.pipelines.move_phone_numbers_map
    params:
    - name: entity_kind
      default: MyModel
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;manipulating-a-raw-datastore-entity:f509f31b4c10397cd1059cd7982b595f&#34;&gt;Manipulating a raw datastore entity&lt;/h2&gt;

&lt;p&gt;Our &lt;code&gt;raw_datastore_map&lt;/code&gt; function to use the datastore entity in its raw form. The raw form of the datastore entity provides a dictionary like interface that we can use to manipulate the entity. With this interface we can move the phone number to the correct field.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def move_phone_numbers_map(entity):
    phone_number = entity.get(&#39;phone_number&#39;)
    if phone_number:
        entity[&#39;work_number&#39;] = phone_number
    del entity[&#39;phone_number&#39;]
    
    yield op.db.Put(entity)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Using &lt;code&gt;op.db.Put&lt;/code&gt; will put the entity to the datastore using the raw datastore
API, thereby bypassing any ndb hooks that are in place.  For more information on
the raw datastore API the best resource is the source code itself, available
from the &lt;a href=&#34;https://code.google.com/p/googleappengine/source/browse/trunk/python/google/appengine/api/datastore.py&#34;&gt;App Engine SDK
repository&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>How to bypass the auto_now property option during an ndb put</title>
      <link>http://sookocheff.com/posts/2014-05-28-how-to-bypass-the-auto-now-property-option-during-an-ndb-put/</link>
      <pubDate>Wed, 28 May 2014 05:55:48 UTC</pubDate>
      <author>kevin.sookocheff@gmail.com (Kevin Sookocheff)</author>
      <guid>http://sookocheff.com/posts/2014-05-28-how-to-bypass-the-auto-now-property-option-during-an-ndb-put/</guid>
      <description>&lt;p&gt;In App Engine the &lt;code&gt;auto_now&lt;/code&gt; option sets a property to the current date/time
whenever the entity is created or updated. This is a great feature for tracking
the time when an entity was last updated. However, sometimes you may want to put
an entity without updating an &lt;code&gt;auto_now&lt;/code&gt; timestamp. This article will show you
how.&lt;/p&gt;

&lt;p&gt;First, let&amp;rsquo;s start with a very basic ndb model with an &lt;code&gt;updated&lt;/code&gt; property having
the &lt;code&gt;auto_now&lt;/code&gt; option set to &lt;code&gt;True&lt;/code&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from google.appengine.ext import ndb

class Article(ndb.model):
    title = ndb.model.StringProperty()
    updated = ndb.model.DateTimeProperty(auto_now=True)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now, let&amp;rsquo;s put the entity to the datastore &lt;em&gt;without updating the timestamp&lt;/em&gt; and
&lt;em&gt;completely bypassing the &lt;code&gt;auto_now&lt;/code&gt; option&lt;/em&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;article = Article(title=&#39;Python versus Ruby&#39;)
article._properties[&#39;updated&#39;].auto_now = False
article.put()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;It&amp;rsquo;s pretty simple, but with caveats. Putting the entity using the code above
will store the updated entity in the instance cache (and memcache). If we get
the entity it will be retrieved from the instance cache with the &lt;code&gt;auto_now&lt;/code&gt;
property still set to &lt;code&gt;False&lt;/code&gt;. This can have unwanted side-effects because
subsequent updates to the entity will not trigger the &lt;code&gt;auto_now&lt;/code&gt; functionality.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;article = Article(title=&#39;Python versus Ruby&#39;)
article._properties[&#39;updated&#39;].auto_now = False
key = article.put() # Put the entity with the auto_now option set to False

article = key.get() # Get the entity from instance cache
article.title = &#39;Python versus Go&#39;
article.put() # Put the entity with the auto_now option *still* set to False
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You can set the &lt;code&gt;auto_now&lt;/code&gt; option to &lt;code&gt;True&lt;/code&gt; again to re-enable the functionality.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;article = Article(title=&#39;Python versus Ruby&#39;)
article._properties[&#39;updated&#39;].auto_now = False
key = article.put()

article._properties[&#39;updated&#39;].auto_now = True
article = key.get() # Get the entity from instance cache
article.title = &#39;Python versus Go&#39;
article.put() # Puts the entity with the auto_now option set to True
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;For more information on ndb caching &lt;a href=&#34;https://developers.google.com/appengine/docs/python/ndb/cache&#34;&gt;refer to the
documentation&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
